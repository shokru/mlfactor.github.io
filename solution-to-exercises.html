<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>B Solution to exercises | Machine Learning for Factor Investing</title>
  <meta name="description" content="B Solution to exercises | Machine Learning for Factor Investing" />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="B Solution to exercises | Machine Learning for Factor Investing" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="B Solution to exercises | Machine Learning for Factor Investing" />
  
  
  

<meta name="author" content="Guillaume Coqueret and Tony Guida" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-description.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="preface.html"><a href="preface.html#what-this-book-is-not-about"><i class="fa fa-check"></i><b>1.1</b> What this book is not about</a></li>
<li class="chapter" data-level="1.2" data-path="preface.html"><a href="preface.html#the-targeted-audience"><i class="fa fa-check"></i><b>1.2</b> The targeted audience</a></li>
<li class="chapter" data-level="1.3" data-path="preface.html"><a href="preface.html#how-this-book-is-structured"><i class="fa fa-check"></i><b>1.3</b> How this book is structured</a></li>
<li class="chapter" data-level="1.4" data-path="preface.html"><a href="preface.html#companion-website"><i class="fa fa-check"></i><b>1.4</b> Companion website</a></li>
<li class="chapter" data-level="1.5" data-path="preface.html"><a href="preface.html#why-r"><i class="fa fa-check"></i><b>1.5</b> Why R?</a></li>
<li class="chapter" data-level="1.6" data-path="preface.html"><a href="preface.html#coding-instructions"><i class="fa fa-check"></i><b>1.6</b> Coding instructions</a></li>
<li class="chapter" data-level="1.7" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i><b>1.7</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.8" data-path="preface.html"><a href="preface.html#future-developments"><i class="fa fa-check"></i><b>1.8</b> Future developments</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="notdata.html"><a href="notdata.html"><i class="fa fa-check"></i><b>2</b> Notations and data</a><ul>
<li class="chapter" data-level="2.1" data-path="notdata.html"><a href="notdata.html#notations"><i class="fa fa-check"></i><b>2.1</b> Notations</a></li>
<li class="chapter" data-level="2.2" data-path="notdata.html"><a href="notdata.html#dataset"><i class="fa fa-check"></i><b>2.2</b> Dataset</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>3</b> Introduction</a><ul>
<li class="chapter" data-level="3.1" data-path="intro.html"><a href="intro.html#context"><i class="fa fa-check"></i><b>3.1</b> Context</a></li>
<li class="chapter" data-level="3.2" data-path="intro.html"><a href="intro.html#portfolio-construction-the-workflow"><i class="fa fa-check"></i><b>3.2</b> Portfolio construction: the workflow</a></li>
<li class="chapter" data-level="3.3" data-path="intro.html"><a href="intro.html#machine-learning-is-no-magic-wand"><i class="fa fa-check"></i><b>3.3</b> Machine Learning is no Magic Wand</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="factor.html"><a href="factor.html"><i class="fa fa-check"></i><b>4</b> Factor investing and asset pricing anomalies</a><ul>
<li class="chapter" data-level="4.1" data-path="factor.html"><a href="factor.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="factor.html"><a href="factor.html#detecting-anomalies"><i class="fa fa-check"></i><b>4.2</b> Detecting anomalies</a><ul>
<li class="chapter" data-level="4.2.1" data-path="factor.html"><a href="factor.html#simple-portfolio-sorts"><i class="fa fa-check"></i><b>4.2.1</b> Simple portfolio sorts</a></li>
<li class="chapter" data-level="4.2.2" data-path="factor.html"><a href="factor.html#factors"><i class="fa fa-check"></i><b>4.2.2</b> Factors</a></li>
<li class="chapter" data-level="4.2.3" data-path="factor.html"><a href="factor.html#predictive-regressions-sorts-and-p-value-issues"><i class="fa fa-check"></i><b>4.2.3</b> Predictive regressions, sorts, and p-value issues</a></li>
<li class="chapter" data-level="4.2.4" data-path="factor.html"><a href="factor.html#fama-macbeth-regressions"><i class="fa fa-check"></i><b>4.2.4</b> Fama-Macbeth regressions</a></li>
<li class="chapter" data-level="4.2.5" data-path="factor.html"><a href="factor.html#factor-competition"><i class="fa fa-check"></i><b>4.2.5</b> Factor competition</a></li>
<li class="chapter" data-level="4.2.6" data-path="factor.html"><a href="factor.html#advanced-techniques"><i class="fa fa-check"></i><b>4.2.6</b> Advanced techniques</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="factor.html"><a href="factor.html#factors-or-characteristics"><i class="fa fa-check"></i><b>4.3</b> Factors or characteristics?</a></li>
<li class="chapter" data-level="4.4" data-path="factor.html"><a href="factor.html#momentum-and-timing"><i class="fa fa-check"></i><b>4.4</b> Momentum and timing</a><ul>
<li class="chapter" data-level="4.4.1" data-path="factor.html"><a href="factor.html#factor-momentum"><i class="fa fa-check"></i><b>4.4.1</b> Factor momentum</a></li>
<li class="chapter" data-level="4.4.2" data-path="factor.html"><a href="factor.html#factor-timing"><i class="fa fa-check"></i><b>4.4.2</b> Factor timing</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="factor.html"><a href="factor.html#the-link-with-machine-learning"><i class="fa fa-check"></i><b>4.5</b> The link with machine learning</a><ul>
<li class="chapter" data-level="4.5.1" data-path="factor.html"><a href="factor.html#a-short-list-of-recent-references"><i class="fa fa-check"></i><b>4.5.1</b> A short list of recent references</a></li>
<li class="chapter" data-level="4.5.2" data-path="factor.html"><a href="factor.html#explicit-connexions-with-asset-pricing-models"><i class="fa fa-check"></i><b>4.5.2</b> Explicit connexions with asset pricing models</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="factor.html"><a href="factor.html#coding-exercises"><i class="fa fa-check"></i><b>4.6</b> Coding exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Data.html"><a href="Data.html"><i class="fa fa-check"></i><b>5</b> Data preprocessing</a><ul>
<li class="chapter" data-level="5.1" data-path="Data.html"><a href="Data.html#know-your-data"><i class="fa fa-check"></i><b>5.1</b> Know your data</a></li>
<li class="chapter" data-level="5.2" data-path="Data.html"><a href="Data.html#missing-data"><i class="fa fa-check"></i><b>5.2</b> Missing data</a></li>
<li class="chapter" data-level="5.3" data-path="Data.html"><a href="Data.html#outlier-detection"><i class="fa fa-check"></i><b>5.3</b> Outlier detection</a></li>
<li class="chapter" data-level="5.4" data-path="Data.html"><a href="Data.html#feateng"><i class="fa fa-check"></i><b>5.4</b> Feature engineering</a><ul>
<li class="chapter" data-level="5.4.1" data-path="Data.html"><a href="Data.html#feature-selection"><i class="fa fa-check"></i><b>5.4.1</b> Feature selection</a></li>
<li class="chapter" data-level="5.4.2" data-path="Data.html"><a href="Data.html#scaling"><i class="fa fa-check"></i><b>5.4.2</b> Scaling the predictors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="Data.html"><a href="Data.html#labelling"><i class="fa fa-check"></i><b>5.5</b> Labelling</a><ul>
<li class="chapter" data-level="5.5.1" data-path="Data.html"><a href="Data.html#simple-labels"><i class="fa fa-check"></i><b>5.5.1</b> Simple labels</a></li>
<li class="chapter" data-level="5.5.2" data-path="Data.html"><a href="Data.html#categorical-labels"><i class="fa fa-check"></i><b>5.5.2</b> Categorical labels</a></li>
<li class="chapter" data-level="5.5.3" data-path="Data.html"><a href="Data.html#the-triple-barrier-method"><i class="fa fa-check"></i><b>5.5.3</b> The triple barrier method</a></li>
<li class="chapter" data-level="5.5.4" data-path="Data.html"><a href="Data.html#filtering-the-sample"><i class="fa fa-check"></i><b>5.5.4</b> Filtering the sample</a></li>
<li class="chapter" data-level="5.5.5" data-path="Data.html"><a href="Data.html#horizons"><i class="fa fa-check"></i><b>5.5.5</b> Return horizons</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="Data.html"><a href="Data.html#pers"><i class="fa fa-check"></i><b>5.6</b> Handling persistence</a></li>
<li class="chapter" data-level="5.7" data-path="Data.html"><a href="Data.html#extensions"><i class="fa fa-check"></i><b>5.7</b> Extensions</a><ul>
<li class="chapter" data-level="5.7.1" data-path="Data.html"><a href="Data.html#transforming-features"><i class="fa fa-check"></i><b>5.7.1</b> Transforming features</a></li>
<li class="chapter" data-level="5.7.2" data-path="Data.html"><a href="Data.html#macrovar"><i class="fa fa-check"></i><b>5.7.2</b> Macro-economic variables</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="Data.html"><a href="Data.html#additional-code-and-results"><i class="fa fa-check"></i><b>5.8</b> Additional code and results</a><ul>
<li class="chapter" data-level="5.8.1" data-path="Data.html"><a href="Data.html#impact-of-rescaling-graphical-representation"><i class="fa fa-check"></i><b>5.8.1</b> Impact of rescaling: graphical representation</a></li>
<li class="chapter" data-level="5.8.2" data-path="Data.html"><a href="Data.html#impact-of-rescaling-toy-example"><i class="fa fa-check"></i><b>5.8.2</b> Impact of rescaling: toy example</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="Data.html"><a href="Data.html#coding-exercises-1"><i class="fa fa-check"></i><b>5.9</b> Coding exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lasso.html"><a href="lasso.html"><i class="fa fa-check"></i><b>6</b> Penalized regressions and sparse hedging for minimum variance portfolios</a><ul>
<li class="chapter" data-level="6.1" data-path="lasso.html"><a href="lasso.html#penalised-regressions"><i class="fa fa-check"></i><b>6.1</b> Penalised regressions</a><ul>
<li class="chapter" data-level="6.1.1" data-path="lasso.html"><a href="lasso.html#simple-regressions"><i class="fa fa-check"></i><b>6.1.1</b> Simple regressions</a></li>
<li class="chapter" data-level="6.1.2" data-path="lasso.html"><a href="lasso.html#forms-of-penalizations"><i class="fa fa-check"></i><b>6.1.2</b> Forms of penalizations</a></li>
<li class="chapter" data-level="6.1.3" data-path="lasso.html"><a href="lasso.html#illustrations"><i class="fa fa-check"></i><b>6.1.3</b> Illustrations</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="lasso.html"><a href="lasso.html#sparse-hedging-for-minimum-variance-portfolios"><i class="fa fa-check"></i><b>6.2</b> Sparse hedging for minimum variance portfolios</a><ul>
<li class="chapter" data-level="6.2.1" data-path="lasso.html"><a href="lasso.html#presentation-and-derivations"><i class="fa fa-check"></i><b>6.2.1</b> Presentation and derivations</a></li>
<li class="chapter" data-level="6.2.2" data-path="lasso.html"><a href="lasso.html#sparseex"><i class="fa fa-check"></i><b>6.2.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="lasso.html"><a href="lasso.html#predictive-regressions"><i class="fa fa-check"></i><b>6.3</b> Predictive regressions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="lasso.html"><a href="lasso.html#literature-review-and-principle"><i class="fa fa-check"></i><b>6.3.1</b> Literature review and principle</a></li>
<li class="chapter" data-level="6.3.2" data-path="lasso.html"><a href="lasso.html#code-and-results"><i class="fa fa-check"></i><b>6.3.2</b> Code and results</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="lasso.html"><a href="lasso.html#coding-exercises-2"><i class="fa fa-check"></i><b>6.4</b> Coding exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="trees.html"><a href="trees.html"><i class="fa fa-check"></i><b>7</b> Tree-based methods</a><ul>
<li class="chapter" data-level="7.1" data-path="trees.html"><a href="trees.html#simple-trees"><i class="fa fa-check"></i><b>7.1</b> Simple trees</a><ul>
<li class="chapter" data-level="7.1.1" data-path="trees.html"><a href="trees.html#principle"><i class="fa fa-check"></i><b>7.1.1</b> Principle</a></li>
<li class="chapter" data-level="7.1.2" data-path="trees.html"><a href="trees.html#further-details-on-classification"><i class="fa fa-check"></i><b>7.1.2</b> Further details on classification</a></li>
<li class="chapter" data-level="7.1.3" data-path="trees.html"><a href="trees.html#pruning-criteria"><i class="fa fa-check"></i><b>7.1.3</b> Pruning criteria</a></li>
<li class="chapter" data-level="7.1.4" data-path="trees.html"><a href="trees.html#code-and-interpretation"><i class="fa fa-check"></i><b>7.1.4</b> Code and interpretation</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="trees.html"><a href="trees.html#random-forests"><i class="fa fa-check"></i><b>7.2</b> Random forests</a><ul>
<li class="chapter" data-level="7.2.1" data-path="trees.html"><a href="trees.html#principle-1"><i class="fa fa-check"></i><b>7.2.1</b> Principle</a></li>
<li class="chapter" data-level="7.2.2" data-path="trees.html"><a href="trees.html#code-and-results-1"><i class="fa fa-check"></i><b>7.2.2</b> Code and results</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="trees.html"><a href="trees.html#adaboost"><i class="fa fa-check"></i><b>7.3</b> Boosted trees: Adaboost</a><ul>
<li class="chapter" data-level="7.3.1" data-path="trees.html"><a href="trees.html#methodology"><i class="fa fa-check"></i><b>7.3.1</b> Methodology</a></li>
<li class="chapter" data-level="7.3.2" data-path="trees.html"><a href="trees.html#illustration"><i class="fa fa-check"></i><b>7.3.2</b> Illustration</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="trees.html"><a href="trees.html#boosted-trees-extreme-gradient-boosting"><i class="fa fa-check"></i><b>7.4</b> Boosted trees: extreme gradient boosting</a><ul>
<li class="chapter" data-level="7.4.1" data-path="trees.html"><a href="trees.html#managing-loss"><i class="fa fa-check"></i><b>7.4.1</b> Managing Loss</a></li>
<li class="chapter" data-level="7.4.2" data-path="trees.html"><a href="trees.html#penalisation"><i class="fa fa-check"></i><b>7.4.2</b> Penalisation</a></li>
<li class="chapter" data-level="7.4.3" data-path="trees.html"><a href="trees.html#aggregation"><i class="fa fa-check"></i><b>7.4.3</b> Aggregation</a></li>
<li class="chapter" data-level="7.4.4" data-path="trees.html"><a href="trees.html#tree-structure"><i class="fa fa-check"></i><b>7.4.4</b> Tree structure</a></li>
<li class="chapter" data-level="7.4.5" data-path="trees.html"><a href="trees.html#boostext"><i class="fa fa-check"></i><b>7.4.5</b> Extensions</a></li>
<li class="chapter" data-level="7.4.6" data-path="trees.html"><a href="trees.html#boostcode"><i class="fa fa-check"></i><b>7.4.6</b> Code and results</a></li>
<li class="chapter" data-level="7.4.7" data-path="trees.html"><a href="trees.html#instweight"><i class="fa fa-check"></i><b>7.4.7</b> Instance weighting</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="trees.html"><a href="trees.html#discussion"><i class="fa fa-check"></i><b>7.5</b> Discussion</a></li>
<li class="chapter" data-level="7.6" data-path="trees.html"><a href="trees.html#coding-exercises-3"><i class="fa fa-check"></i><b>7.6</b> Coding exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="NN.html"><a href="NN.html"><i class="fa fa-check"></i><b>8</b> Neural networks</a><ul>
<li class="chapter" data-level="8.1" data-path="NN.html"><a href="NN.html#the-original-perceptron"><i class="fa fa-check"></i><b>8.1</b> The original perceptron</a></li>
<li class="chapter" data-level="8.2" data-path="NN.html"><a href="NN.html#multilayer-perceptron"><i class="fa fa-check"></i><b>8.2</b> Multilayer perceptron</a><ul>
<li class="chapter" data-level="8.2.1" data-path="NN.html"><a href="NN.html#introduction-and-notations"><i class="fa fa-check"></i><b>8.2.1</b> Introduction and notations</a></li>
<li class="chapter" data-level="8.2.2" data-path="NN.html"><a href="NN.html#universal-approximation"><i class="fa fa-check"></i><b>8.2.2</b> Universal approximation</a></li>
<li class="chapter" data-level="8.2.3" data-path="NN.html"><a href="NN.html#backprop"><i class="fa fa-check"></i><b>8.2.3</b> Learning via back-propagation</a></li>
<li class="chapter" data-level="8.2.4" data-path="NN.html"><a href="NN.html#further-details-on-classification-1"><i class="fa fa-check"></i><b>8.2.4</b> Further details on classification</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="NN.html"><a href="NN.html#howdeep"><i class="fa fa-check"></i><b>8.3</b> How deep should we go? And other practical issues</a><ul>
<li class="chapter" data-level="8.3.1" data-path="NN.html"><a href="NN.html#architectural-choices"><i class="fa fa-check"></i><b>8.3.1</b> Architectural choices</a></li>
<li class="chapter" data-level="8.3.2" data-path="NN.html"><a href="NN.html#frequency-of-weight-updates-and-learning-duration"><i class="fa fa-check"></i><b>8.3.2</b> Frequency of weight updates and learning duration</a></li>
<li class="chapter" data-level="8.3.3" data-path="NN.html"><a href="NN.html#penalizations-and-dropout"><i class="fa fa-check"></i><b>8.3.3</b> Penalizations and dropout</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="NN.html"><a href="NN.html#code-samples-and-comments-for-vanilla-mlp"><i class="fa fa-check"></i><b>8.4</b> Code samples and comments for vanilla MLP</a><ul>
<li class="chapter" data-level="8.4.1" data-path="NN.html"><a href="NN.html#regression-example"><i class="fa fa-check"></i><b>8.4.1</b> Regression example</a></li>
<li class="chapter" data-level="8.4.2" data-path="NN.html"><a href="NN.html#classification-example"><i class="fa fa-check"></i><b>8.4.2</b> Classification example</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="NN.html"><a href="NN.html#recurrent-networks"><i class="fa fa-check"></i><b>8.5</b> Recurrent networks</a><ul>
<li class="chapter" data-level="8.5.1" data-path="NN.html"><a href="NN.html#presentation"><i class="fa fa-check"></i><b>8.5.1</b> Presentation</a></li>
<li class="chapter" data-level="8.5.2" data-path="NN.html"><a href="NN.html#code-and-results-2"><i class="fa fa-check"></i><b>8.5.2</b> Code and results</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="NN.html"><a href="NN.html#other-common-architectures"><i class="fa fa-check"></i><b>8.6</b> Other common architectures</a><ul>
<li class="chapter" data-level="8.6.1" data-path="NN.html"><a href="NN.html#generative-aversarial-networks"><i class="fa fa-check"></i><b>8.6.1</b> Generative adversarial networks</a></li>
<li class="chapter" data-level="8.6.2" data-path="NN.html"><a href="NN.html#autoencoders"><i class="fa fa-check"></i><b>8.6.2</b> Auto-encoders</a></li>
<li class="chapter" data-level="8.6.3" data-path="NN.html"><a href="NN.html#a-word-on-convolutional-networks"><i class="fa fa-check"></i><b>8.6.3</b> A word on convolutional networks</a></li>
<li class="chapter" data-level="8.6.4" data-path="NN.html"><a href="NN.html#advanced-architectures"><i class="fa fa-check"></i><b>8.6.4</b> Advanced architectures</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="NN.html"><a href="NN.html#coding-exercise"><i class="fa fa-check"></i><b>8.7</b> Coding exercise</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>9</b> Support vector machines</a><ul>
<li class="chapter" data-level="9.1" data-path="svm.html"><a href="svm.html#svm-for-classification"><i class="fa fa-check"></i><b>9.1</b> SVM for classification</a></li>
<li class="chapter" data-level="9.2" data-path="svm.html"><a href="svm.html#svm-for-regression"><i class="fa fa-check"></i><b>9.2</b> SVM for regression</a></li>
<li class="chapter" data-level="9.3" data-path="svm.html"><a href="svm.html#practice"><i class="fa fa-check"></i><b>9.3</b> Practice</a></li>
<li class="chapter" data-level="9.4" data-path="svm.html"><a href="svm.html#coding-exercises-4"><i class="fa fa-check"></i><b>9.4</b> Coding exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>10</b> Bayesian methods</a><ul>
<li class="chapter" data-level="10.1" data-path="bayes.html"><a href="bayes.html#the-bayesian-framework"><i class="fa fa-check"></i><b>10.1</b> The Bayesian framework</a></li>
<li class="chapter" data-level="10.2" data-path="bayes.html"><a href="bayes.html#bayesian-sampling"><i class="fa fa-check"></i><b>10.2</b> Bayesian sampling</a><ul>
<li class="chapter" data-level="10.2.1" data-path="bayes.html"><a href="bayes.html#gibbs-sampling"><i class="fa fa-check"></i><b>10.2.1</b> Gibbs sampling</a></li>
<li class="chapter" data-level="10.2.2" data-path="bayes.html"><a href="bayes.html#metropolis-hastings-sampling"><i class="fa fa-check"></i><b>10.2.2</b> Metropolis-Hastings sampling</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="bayes.html"><a href="bayes.html#bayesian-linear-regression"><i class="fa fa-check"></i><b>10.3</b> Bayesian linear regression</a></li>
<li class="chapter" data-level="10.4" data-path="bayes.html"><a href="bayes.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>10.4</b> Naive Bayes classifier</a></li>
<li class="chapter" data-level="10.5" data-path="bayes.html"><a href="bayes.html#BART"><i class="fa fa-check"></i><b>10.5</b> Bayesian additive trees</a><ul>
<li class="chapter" data-level="10.5.1" data-path="bayes.html"><a href="bayes.html#general-formulation"><i class="fa fa-check"></i><b>10.5.1</b> General formulation</a></li>
<li class="chapter" data-level="10.5.2" data-path="bayes.html"><a href="bayes.html#priors"><i class="fa fa-check"></i><b>10.5.2</b> Priors</a></li>
<li class="chapter" data-level="10.5.3" data-path="bayes.html"><a href="bayes.html#sampling-and-predictions"><i class="fa fa-check"></i><b>10.5.3</b> Sampling and predictions</a></li>
<li class="chapter" data-level="10.5.4" data-path="bayes.html"><a href="bayes.html#code"><i class="fa fa-check"></i><b>10.5.4</b> Code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="valtune.html"><a href="valtune.html"><i class="fa fa-check"></i><b>11</b> Validating and tuning</a><ul>
<li class="chapter" data-level="11.1" data-path="valtune.html"><a href="valtune.html#mlmetrics"><i class="fa fa-check"></i><b>11.1</b> Learning metrics</a><ul>
<li class="chapter" data-level="11.1.1" data-path="valtune.html"><a href="valtune.html#regression-analysis"><i class="fa fa-check"></i><b>11.1.1</b> Regression analysis</a></li>
<li class="chapter" data-level="11.1.2" data-path="valtune.html"><a href="valtune.html#classification-analysis"><i class="fa fa-check"></i><b>11.1.2</b> Classification analysis</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="valtune.html"><a href="valtune.html#validation"><i class="fa fa-check"></i><b>11.2</b> Validation</a><ul>
<li class="chapter" data-level="11.2.1" data-path="valtune.html"><a href="valtune.html#the-variance-bias-tradeoff-theory"><i class="fa fa-check"></i><b>11.2.1</b> The variance-bias tradeoff: theory</a></li>
<li class="chapter" data-level="11.2.2" data-path="valtune.html"><a href="valtune.html#the-variance-bias-tradeoff-illustration"><i class="fa fa-check"></i><b>11.2.2</b> The variance-bias tradeoff: illustration</a></li>
<li class="chapter" data-level="11.2.3" data-path="valtune.html"><a href="valtune.html#the-risk-of-overfitting-principle"><i class="fa fa-check"></i><b>11.2.3</b> The risk of overfitting: principle</a></li>
<li class="chapter" data-level="11.2.4" data-path="valtune.html"><a href="valtune.html#the-risk-of-overfitting-some-solutions"><i class="fa fa-check"></i><b>11.2.4</b> The risk of overfitting: some solutions</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="valtune.html"><a href="valtune.html#the-search-for-good-hyperparameters"><i class="fa fa-check"></i><b>11.3</b> The search for good hyperparameters</a><ul>
<li class="chapter" data-level="11.3.1" data-path="valtune.html"><a href="valtune.html#methods"><i class="fa fa-check"></i><b>11.3.1</b> Methods</a></li>
<li class="chapter" data-level="11.3.2" data-path="valtune.html"><a href="valtune.html#example-grid-search"><i class="fa fa-check"></i><b>11.3.2</b> Example: grid search</a></li>
<li class="chapter" data-level="11.3.3" data-path="valtune.html"><a href="valtune.html#example-bayesian-optimization"><i class="fa fa-check"></i><b>11.3.3</b> Example: Bayesian optimization</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="valtune.html"><a href="valtune.html#short-discussion-on-validation-in-backtests"><i class="fa fa-check"></i><b>11.4</b> Short discussion on validation in backtests</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ensemble.html"><a href="ensemble.html"><i class="fa fa-check"></i><b>12</b> Ensemble models</a><ul>
<li class="chapter" data-level="12.1" data-path="ensemble.html"><a href="ensemble.html#linear-ensembles"><i class="fa fa-check"></i><b>12.1</b> Linear ensembles</a><ul>
<li class="chapter" data-level="12.1.1" data-path="ensemble.html"><a href="ensemble.html#principles"><i class="fa fa-check"></i><b>12.1.1</b> Principles</a></li>
<li class="chapter" data-level="12.1.2" data-path="ensemble.html"><a href="ensemble.html#example"><i class="fa fa-check"></i><b>12.1.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="ensemble.html"><a href="ensemble.html#stacked-ensembles"><i class="fa fa-check"></i><b>12.2</b> Stacked ensembles</a><ul>
<li class="chapter" data-level="12.2.1" data-path="ensemble.html"><a href="ensemble.html#two-stage-training"><i class="fa fa-check"></i><b>12.2.1</b> Two stage training</a></li>
<li class="chapter" data-level="12.2.2" data-path="ensemble.html"><a href="ensemble.html#code-and-results-3"><i class="fa fa-check"></i><b>12.2.2</b> Code and results</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ensemble.html"><a href="ensemble.html#extensions-1"><i class="fa fa-check"></i><b>12.3</b> Extensions</a><ul>
<li class="chapter" data-level="12.3.1" data-path="ensemble.html"><a href="ensemble.html#exogenous-variables"><i class="fa fa-check"></i><b>12.3.1</b> Exogenous variables</a></li>
<li class="chapter" data-level="12.3.2" data-path="ensemble.html"><a href="ensemble.html#shrinking-inter-model-correlations"><i class="fa fa-check"></i><b>12.3.2</b> Shrinking inter-model correlations</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="ensemble.html"><a href="ensemble.html#exercise"><i class="fa fa-check"></i><b>12.4</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="backtest.html"><a href="backtest.html"><i class="fa fa-check"></i><b>13</b> Portfolio backtesting</a><ul>
<li class="chapter" data-level="13.1" data-path="backtest.html"><a href="backtest.html#protocol"><i class="fa fa-check"></i><b>13.1</b> Setting the protocol</a></li>
<li class="chapter" data-level="13.2" data-path="backtest.html"><a href="backtest.html#turning-signals-into-portfolio-weights"><i class="fa fa-check"></i><b>13.2</b> Turning signals into portfolio weights</a></li>
<li class="chapter" data-level="13.3" data-path="backtest.html"><a href="backtest.html#perfmet"><i class="fa fa-check"></i><b>13.3</b> Performance metrics</a><ul>
<li class="chapter" data-level="13.3.1" data-path="backtest.html"><a href="backtest.html#discussion-1"><i class="fa fa-check"></i><b>13.3.1</b> Discussion</a></li>
<li class="chapter" data-level="13.3.2" data-path="backtest.html"><a href="backtest.html#pure-performance-and-risk-indicators"><i class="fa fa-check"></i><b>13.3.2</b> Pure performance and risk indicators</a></li>
<li class="chapter" data-level="13.3.3" data-path="backtest.html"><a href="backtest.html#factor-based-evaluation"><i class="fa fa-check"></i><b>13.3.3</b> Factor-based evaluation</a></li>
<li class="chapter" data-level="13.3.4" data-path="backtest.html"><a href="backtest.html#risk-adjusted-measures"><i class="fa fa-check"></i><b>13.3.4</b> Risk-adjusted measures</a></li>
<li class="chapter" data-level="13.3.5" data-path="backtest.html"><a href="backtest.html#transaction-costs-and-turnover"><i class="fa fa-check"></i><b>13.3.5</b> Transaction costs and turnover</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="backtest.html"><a href="backtest.html#common-errors-and-issues"><i class="fa fa-check"></i><b>13.4</b> Common errors and issues</a><ul>
<li class="chapter" data-level="13.4.1" data-path="backtest.html"><a href="backtest.html#forward-looking-data"><i class="fa fa-check"></i><b>13.4.1</b> Forward looking data</a></li>
<li class="chapter" data-level="13.4.2" data-path="backtest.html"><a href="backtest.html#backtest-overfitting"><i class="fa fa-check"></i><b>13.4.2</b> Backtest overfitting</a></li>
<li class="chapter" data-level="13.4.3" data-path="backtest.html"><a href="backtest.html#simple-saveguards"><i class="fa fa-check"></i><b>13.4.3</b> Simple saveguards</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="backtest.html"><a href="backtest.html#implication-of-non-stationarity-forecasting-is-hard"><i class="fa fa-check"></i><b>13.5</b> Implication of non-stationarity: forecasting is hard</a><ul>
<li class="chapter" data-level="13.5.1" data-path="backtest.html"><a href="backtest.html#general-comments"><i class="fa fa-check"></i><b>13.5.1</b> General comments</a></li>
<li class="chapter" data-level="13.5.2" data-path="backtest.html"><a href="backtest.html#the-no-free-lunch-theorem"><i class="fa fa-check"></i><b>13.5.2</b> The no free lunch theorem</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="backtest.html"><a href="backtest.html#example-1"><i class="fa fa-check"></i><b>13.6</b> Example</a></li>
<li class="chapter" data-level="13.7" data-path="backtest.html"><a href="backtest.html#coding-exercises-5"><i class="fa fa-check"></i><b>13.7</b> Coding exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="interp.html"><a href="interp.html"><i class="fa fa-check"></i><b>14</b> Interpretability</a><ul>
<li class="chapter" data-level="14.1" data-path="interp.html"><a href="interp.html#global-interpretations"><i class="fa fa-check"></i><b>14.1</b> Global interpretations</a><ul>
<li class="chapter" data-level="14.1.1" data-path="interp.html"><a href="interp.html#variable-importance"><i class="fa fa-check"></i><b>14.1.1</b> Variable importance (tree-based)</a></li>
<li class="chapter" data-level="14.1.2" data-path="interp.html"><a href="interp.html#variable-importance-agnostic"><i class="fa fa-check"></i><b>14.1.2</b> Variable importance (agnostic)</a></li>
<li class="chapter" data-level="14.1.3" data-path="interp.html"><a href="interp.html#partial-dependence-plot"><i class="fa fa-check"></i><b>14.1.3</b> Partial dependence plot</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="interp.html"><a href="interp.html#local-interpretations"><i class="fa fa-check"></i><b>14.2</b> Local interpretations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="interp.html"><a href="interp.html#lime"><i class="fa fa-check"></i><b>14.2.1</b> LIME</a></li>
<li class="chapter" data-level="14.2.2" data-path="interp.html"><a href="interp.html#shapley-values"><i class="fa fa-check"></i><b>14.2.2</b> Shapley values</a></li>
<li class="chapter" data-level="14.2.3" data-path="interp.html"><a href="interp.html#breakdown"><i class="fa fa-check"></i><b>14.2.3</b> Breakdown</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="causality.html"><a href="causality.html"><i class="fa fa-check"></i><b>15</b> Two key concepts: causality and non-stationarity</a><ul>
<li class="chapter" data-level="15.1" data-path="causality.html"><a href="causality.html#causality-1"><i class="fa fa-check"></i><b>15.1</b> Causality</a><ul>
<li class="chapter" data-level="15.1.1" data-path="causality.html"><a href="causality.html#granger"><i class="fa fa-check"></i><b>15.1.1</b> Granger causality</a></li>
<li class="chapter" data-level="15.1.2" data-path="causality.html"><a href="causality.html#causal-additive-models"><i class="fa fa-check"></i><b>15.1.2</b> Causal additive models</a></li>
<li class="chapter" data-level="15.1.3" data-path="causality.html"><a href="causality.html#structural-time-series-models"><i class="fa fa-check"></i><b>15.1.3</b> Structural time-series models</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="causality.html"><a href="causality.html#nonstat"><i class="fa fa-check"></i><b>15.2</b> Dealing with changing environments</a><ul>
<li class="chapter" data-level="15.2.1" data-path="causality.html"><a href="causality.html#non-stationarity-an-obvious-illustration"><i class="fa fa-check"></i><b>15.2.1</b> Non-stationarity: an obvious illustration</a></li>
<li class="chapter" data-level="15.2.2" data-path="causality.html"><a href="causality.html#online-learning"><i class="fa fa-check"></i><b>15.2.2</b> Online learning</a></li>
<li class="chapter" data-level="15.2.3" data-path="causality.html"><a href="causality.html#homogeneous-transfer-learning"><i class="fa fa-check"></i><b>15.2.3</b> Homogeneous transfer learning</a></li>
<li class="chapter" data-level="15.2.4" data-path="causality.html"><a href="causality.html#active-learning"><i class="fa fa-check"></i><b>15.2.4</b> Active learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="unsup.html"><a href="unsup.html"><i class="fa fa-check"></i><b>16</b> Unsupervised learning</a><ul>
<li class="chapter" data-level="16.1" data-path="unsup.html"><a href="unsup.html#corpred"><i class="fa fa-check"></i><b>16.1</b> The problem with correlated predictors</a></li>
<li class="chapter" data-level="16.2" data-path="unsup.html"><a href="unsup.html#principal-component-analysis-and-autoencoders"><i class="fa fa-check"></i><b>16.2</b> Principal component analysis and autoencoders</a><ul>
<li class="chapter" data-level="16.2.1" data-path="unsup.html"><a href="unsup.html#a-bit-of-algebra"><i class="fa fa-check"></i><b>16.2.1</b> A bit of algebra</a></li>
<li class="chapter" data-level="16.2.2" data-path="unsup.html"><a href="unsup.html#pca"><i class="fa fa-check"></i><b>16.2.2</b> PCA</a></li>
<li class="chapter" data-level="16.2.3" data-path="unsup.html"><a href="unsup.html#ae"><i class="fa fa-check"></i><b>16.2.3</b> Autoencoders</a></li>
<li class="chapter" data-level="16.2.4" data-path="unsup.html"><a href="unsup.html#application"><i class="fa fa-check"></i><b>16.2.4</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="unsup.html"><a href="unsup.html#clustering-via-k-means"><i class="fa fa-check"></i><b>16.3</b> Clustering via k-means</a></li>
<li class="chapter" data-level="16.4" data-path="unsup.html"><a href="unsup.html#nearest-neighbors"><i class="fa fa-check"></i><b>16.4</b> Nearest neighbors</a></li>
<li class="chapter" data-level="16.5" data-path="unsup.html"><a href="unsup.html#coding-exercise-1"><i class="fa fa-check"></i><b>16.5</b> Coding exercise</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="RL.html"><a href="RL.html"><i class="fa fa-check"></i><b>17</b> Reinforcement learning</a><ul>
<li class="chapter" data-level="17.1" data-path="RL.html"><a href="RL.html#theoretical-layout"><i class="fa fa-check"></i><b>17.1</b> Theoretical layout</a><ul>
<li class="chapter" data-level="17.1.1" data-path="RL.html"><a href="RL.html#general-framework"><i class="fa fa-check"></i><b>17.1.1</b> General framework</a></li>
<li class="chapter" data-level="17.1.2" data-path="RL.html"><a href="RL.html#q-learning"><i class="fa fa-check"></i><b>17.1.2</b> Q-learning</a></li>
<li class="chapter" data-level="17.1.3" data-path="RL.html"><a href="RL.html#sarsa"><i class="fa fa-check"></i><b>17.1.3</b> SARSA</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="RL.html"><a href="RL.html#the-curse-of-dimensionality"><i class="fa fa-check"></i><b>17.2</b> The curse of dimensionality</a></li>
<li class="chapter" data-level="17.3" data-path="RL.html"><a href="RL.html#policy-gradient"><i class="fa fa-check"></i><b>17.3</b> Policy gradient</a><ul>
<li class="chapter" data-level="17.3.1" data-path="RL.html"><a href="RL.html#principle-2"><i class="fa fa-check"></i><b>17.3.1</b> Principle</a></li>
<li class="chapter" data-level="17.3.2" data-path="RL.html"><a href="RL.html#extensions-2"><i class="fa fa-check"></i><b>17.3.2</b> Extensions</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="RL.html"><a href="RL.html#simple-examples"><i class="fa fa-check"></i><b>17.4</b> Simple examples</a><ul>
<li class="chapter" data-level="17.4.1" data-path="RL.html"><a href="RL.html#q-learning-with-simulations"><i class="fa fa-check"></i><b>17.4.1</b> Q-learning with simulations</a></li>
<li class="chapter" data-level="17.4.2" data-path="RL.html"><a href="RL.html#RLemp2"><i class="fa fa-check"></i><b>17.4.2</b> Q-learning with market data</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="RL.html"><a href="RL.html#concluding-remarks"><i class="fa fa-check"></i><b>17.5</b> Concluding remarks</a></li>
<li class="chapter" data-level="17.6" data-path="RL.html"><a href="RL.html#exercises"><i class="fa fa-check"></i><b>17.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="NLP.html"><a href="NLP.html"><i class="fa fa-check"></i><b>18</b> Natural Language Processing</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="data-description.html"><a href="data-description.html"><i class="fa fa-check"></i><b>A</b> Data Description</a></li>
<li class="chapter" data-level="B" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html"><i class="fa fa-check"></i><b>B</b> Solution to exercises</a><ul>
<li class="chapter" data-level="B.1" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#chapter-4"><i class="fa fa-check"></i><b>B.1</b> Chapter 4</a></li>
<li class="chapter" data-level="B.2" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#chapter-5"><i class="fa fa-check"></i><b>B.2</b> Chapter 5</a></li>
<li class="chapter" data-level="B.3" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#chapter-6"><i class="fa fa-check"></i><b>B.3</b> Chapter 6</a></li>
<li class="chapter" data-level="B.4" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#chapter-7"><i class="fa fa-check"></i><b>B.4</b> Chapter 7</a></li>
<li class="chapter" data-level="B.5" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#chapter-8-the-autoencoder-model"><i class="fa fa-check"></i><b>B.5</b> Chapter 8: the autoencoder model</a></li>
<li class="chapter" data-level="B.6" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#chapter-9"><i class="fa fa-check"></i><b>B.6</b> Chapter 9</a></li>
<li class="chapter" data-level="B.7" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#chapter-12-ensemble-neural-network"><i class="fa fa-check"></i><b>B.7</b> Chapter 12: ensemble neural network</a></li>
<li class="chapter" data-level="B.8" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#chapter-13"><i class="fa fa-check"></i><b>B.8</b> Chapter 13</a><ul>
<li class="chapter" data-level="B.8.1" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#advanced-weighting-function"><i class="fa fa-check"></i><b>B.8.1</b> Advanced weighting function</a></li>
<li class="chapter" data-level="B.8.2" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#functional-programming-in-the-backtest"><i class="fa fa-check"></i><b>B.8.2</b> Functional programming in the backtest</a></li>
</ul></li>
<li class="chapter" data-level="B.9" data-path="solution-to-exercises.html"><a href="solution-to-exercises.html#chapter-17"><i class="fa fa-check"></i><b>B.9</b> Chapter 17</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>C</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning for Factor Investing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="solution-to-exercises" class="section level1">
<h1><span class="header-section-number">B</span> Solution to exercises</h1>
<div id="chapter-4" class="section level2">
<h2><span class="header-section-number">B.1</span> Chapter 4</h2>
<p>For annual values:
</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb225-1" data-line-number="1">data_ml <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb225-2" data-line-number="2"><span class="st">    </span><span class="kw">group_by</span>(date) <span class="op">%&gt;%</span><span class="st">                                            </span></a>
<a class="sourceLine" id="cb225-3" data-line-number="3"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">growth =</span> Pb <span class="op">&gt;</span><span class="st"> </span><span class="kw">median</span>(Pb)) <span class="op">%&gt;%</span><span class="st">            </span><span class="co"># Creates the sort</span></a>
<a class="sourceLine" id="cb225-4" data-line-number="4"><span class="st">    </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st">                                   </span><span class="co"># Ungroup</span></a>
<a class="sourceLine" id="cb225-5" data-line-number="5"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">year =</span> lubridate<span class="op">::</span><span class="kw">year</span>(date)) <span class="op">%&gt;%</span><span class="st">        </span><span class="co"># Creates a year variable</span></a>
<a class="sourceLine" id="cb225-6" data-line-number="6"><span class="st">    </span><span class="kw">group_by</span>(year, growth) <span class="op">%&gt;%</span><span class="st">                      </span><span class="co"># Analyze by year &amp; sort</span></a>
<a class="sourceLine" id="cb225-7" data-line-number="7"><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">ret =</span> <span class="kw">mean</span>(R1M_Usd)) <span class="op">%&gt;%</span><span class="st">              </span><span class="co"># Compute average return</span></a>
<a class="sourceLine" id="cb225-8" data-line-number="8"><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> ret, <span class="dt">fill =</span> growth)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_col</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># Plot!</span></a>
<a class="sourceLine" id="cb225-9" data-line-number="9"><span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="kw">c</span>(<span class="fl">0.7</span>, <span class="fl">0.8</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex41b"></span>
<img src="ML_factor_files/figure-html/ex41b-1.png" alt="The value factor: annual returns." width="400px" height="150px" />
<p class="caption">
FIGURE B.1: The value factor: annual returns.
</p>
</div>
<p></p>
<p>For monthly values:
</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb226-1" data-line-number="1">returns_m &lt;-<span class="st"> </span>data_ml <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb226-2" data-line-number="2"><span class="st">    </span><span class="kw">group_by</span>(date) <span class="op">%&gt;%</span><span class="st">                                            </span></a>
<a class="sourceLine" id="cb226-3" data-line-number="3"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">growth =</span> Pb <span class="op">&gt;</span><span class="st"> </span><span class="kw">median</span>(Pb)) <span class="op">%&gt;%</span><span class="st">                           </span><span class="co"># Creates the sort</span></a>
<a class="sourceLine" id="cb226-4" data-line-number="4"><span class="st">    </span><span class="kw">group_by</span>(date, growth) <span class="op">%&gt;%</span><span class="st">                                     </span><span class="co"># Analyze by date &amp; sort</span></a>
<a class="sourceLine" id="cb226-5" data-line-number="5"><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">ret =</span> <span class="kw">mean</span>(R1M_Usd)) <span class="op">%&gt;%</span><span class="st">                             </span><span class="co"># Compute average return</span></a>
<a class="sourceLine" id="cb226-6" data-line-number="6"><span class="st">    </span><span class="kw">spread</span>(<span class="dt">key =</span> growth, <span class="dt">value =</span> ret) <span class="op">%&gt;%</span><span class="st">                          </span><span class="co"># Pivot to wide matrix format</span></a>
<a class="sourceLine" id="cb226-7" data-line-number="7"><span class="st">    </span><span class="kw">ungroup</span>()</a>
<a class="sourceLine" id="cb226-8" data-line-number="8"><span class="kw">colnames</span>(returns_m)[<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;value&quot;</span>, <span class="st">&quot;growth&quot;</span>)                     <span class="co"># Changing column names</span></a>
<a class="sourceLine" id="cb226-9" data-line-number="9">returns_m <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb226-10" data-line-number="10"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">value =</span> <span class="kw">cumprod</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>value),                             <span class="co"># From returns to portf. values</span></a>
<a class="sourceLine" id="cb226-11" data-line-number="11">           <span class="dt">growth =</span> <span class="kw">cumprod</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>growth)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb226-12" data-line-number="12"><span class="st">    </span><span class="kw">gather</span>(<span class="dt">key =</span> portfolio, <span class="dt">value =</span> value, <span class="op">-</span>date) <span class="op">%&gt;%</span><span class="st">              </span><span class="co"># Back in tidy format</span></a>
<a class="sourceLine" id="cb226-13" data-line-number="13"><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> date, <span class="dt">y =</span> value, <span class="dt">color =</span> portfolio)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st">     </span><span class="co"># Plot!  </span></a>
<a class="sourceLine" id="cb226-14" data-line-number="14"><span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="kw">c</span>(<span class="fl">0.7</span>, <span class="fl">0.8</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex41"></span>
<img src="ML_factor_files/figure-html/ex41-1.png" alt="The value factor: portfolio values." width="400px" height="150px" />
<p class="caption">
FIGURE B.2: The value factor: portfolio values.
</p>
</div>
<p></p>
<p>Portfolios based on quartiles, using the tidyverse only. We rely heavily on the fact that features are uniforimized, i.e., that their distribution is uniform for each given date. Overall, small firms outperform heavily.</p>

<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb227-1" data-line-number="1">data_ml <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb227-2" data-line-number="2"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">small =</span> Mkt_Cap_6M_Usd <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.25</span>,                        <span class="co"># Small firms...</span></a>
<a class="sourceLine" id="cb227-3" data-line-number="3">           <span class="dt">medium =</span> Mkt_Cap_6M_Usd <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.25</span> <span class="op">&amp;</span><span class="st"> </span>Mkt_Cap_6M_Usd <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.5</span>, </a>
<a class="sourceLine" id="cb227-4" data-line-number="4">           <span class="dt">large =</span> Mkt_Cap_6M_Usd <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">&amp;</span><span class="st"> </span>Mkt_Cap_6M_Usd <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.75</span>,</a>
<a class="sourceLine" id="cb227-5" data-line-number="5">           <span class="dt">xl =</span> Mkt_Cap_6M_Usd <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.75</span>,                            <span class="co"># ...Xlarge firms</span></a>
<a class="sourceLine" id="cb227-6" data-line-number="6">           <span class="dt">year =</span> <span class="kw">year</span>(date)) <span class="op">%&gt;%</span><span class="st">                        </span></a>
<a class="sourceLine" id="cb227-7" data-line-number="7"><span class="st">    </span><span class="kw">group_by</span>(year) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb227-8" data-line-number="8"><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">small =</span> <span class="kw">mean</span>(small <span class="op">*</span><span class="st"> </span>R1M_Usd),                      <span class="co"># Compute avg returns</span></a>
<a class="sourceLine" id="cb227-9" data-line-number="9">              <span class="dt">medium =</span> <span class="kw">mean</span>(medium <span class="op">*</span><span class="st"> </span>R1M_Usd),</a>
<a class="sourceLine" id="cb227-10" data-line-number="10">              <span class="dt">large =</span> <span class="kw">mean</span>(large <span class="op">*</span><span class="st"> </span>R1M_Usd),</a>
<a class="sourceLine" id="cb227-11" data-line-number="11">              <span class="dt">xl =</span> <span class="kw">mean</span>(xl <span class="op">*</span><span class="st"> </span>R1M_Usd)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb227-12" data-line-number="12"><span class="st">    </span><span class="kw">gather</span>(<span class="dt">key =</span> size, <span class="dt">value =</span> return, <span class="op">-</span>year) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb227-13" data-line-number="13"><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> return, <span class="dt">fill =</span> size)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_col</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex43"></span>
<img src="ML_factor_files/figure-html/ex43-1.png" alt="The value factor: portfolio values." width="432" />
<p class="caption">
FIGURE B.3: The value factor: portfolio values.
</p>
</div>
<p></p>
</div>
<div id="chapter-5" class="section level2">
<h2><span class="header-section-number">B.2</span> Chapter 5</h2>
<p>Below, we import a credit spread supplied by Bank of America. Its symbol/ticker is BAMLC0A0CM. We apply the data expansion on the small number of predictors to save memory space. One important trick that should not be overlooked is the uniformization step after the product <a href="Data.html#eq:macrocond">(5.3)</a> is computed. Indeed, we want the new features to have the same properties as the old ones. If we skip this step, distributions will be altered, as we show in one example below.</p>
<p>We start with the data extraction and joining. Its important to join early so as to keep the highest data frequency (daily) in order to replace missing points with <strong>close values</strong>. Joining with monthly data before replacing creates unnecessary lags.</p>

<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb228-1" data-line-number="1"><span class="kw">getSymbols.FRED</span>(<span class="st">&quot;BAMLC0A0CM&quot;</span>,                                    <span class="co"># Extract data</span></a>
<a class="sourceLine" id="cb228-2" data-line-number="2">                <span class="dt">env =</span> <span class="st">&quot;.GlobalEnv&quot;</span>, </a>
<a class="sourceLine" id="cb228-3" data-line-number="3">                <span class="dt">return.class =</span> <span class="st">&quot;xts&quot;</span>)</a></code></pre></div>
<pre><code>## [1] &quot;BAMLC0A0CM&quot;</code></pre>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb230-1" data-line-number="1">cred_spread &lt;-<span class="st"> </span><span class="kw">fortify</span>(BAMLC0A0CM)                               <span class="co"># Transform to dataframe</span></a>
<a class="sourceLine" id="cb230-2" data-line-number="2"><span class="kw">colnames</span>(cred_spread) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;date&quot;</span>, <span class="st">&quot;spread&quot;</span>)                     <span class="co"># Change column name</span></a>
<a class="sourceLine" id="cb230-3" data-line-number="3">cred_spread &lt;-<span class="st"> </span>cred_spread <span class="op">%&gt;%</span><span class="st">                                   </span><span class="co"># Take extraction and...</span></a>
<a class="sourceLine" id="cb230-4" data-line-number="4"><span class="st">    </span><span class="kw">full_join</span>(data_ml <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(date), <span class="dt">by =</span> <span class="st">&quot;date&quot;</span>) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># Join!</span></a>
<a class="sourceLine" id="cb230-5" data-line-number="5"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">spread =</span> <span class="kw">na.locf</span>(spread))                             <span class="co"># Replace NA by previous</span></a>
<a class="sourceLine" id="cb230-6" data-line-number="6">cred_spread &lt;-<span class="st"> </span>cred_spread[<span class="op">!</span><span class="kw">duplicated</span>(cred_spread),]            <span class="co"># Remove duplicates</span></a></code></pre></div>
<p></p>
<p>The creation of the augmented dataset requires some manipulation.</p>

<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb231-1" data-line-number="1">data_cond &lt;-<span class="st"> </span>data_ml <span class="op">%&gt;%</span><span class="st">                                    </span><span class="co"># Create new dataset</span></a>
<a class="sourceLine" id="cb231-2" data-line-number="2"><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="kw">c</span>(<span class="st">&quot;stock_id&quot;</span>, <span class="st">&quot;date&quot;</span>, features_short))</a>
<a class="sourceLine" id="cb231-3" data-line-number="3">names_cred_spread &lt;-<span class="st"> </span><span class="kw">paste0</span>(features_short, <span class="st">&quot;_cred_spread&quot;</span>) <span class="co"># New column names</span></a>
<a class="sourceLine" id="cb231-4" data-line-number="4">feat_cred_spread &lt;-<span class="st"> </span>data_cond <span class="op">%&gt;%</span><span class="st">                           </span><span class="co"># Old values</span></a>
<a class="sourceLine" id="cb231-5" data-line-number="5"><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(features_short)</a>
<a class="sourceLine" id="cb231-6" data-line-number="6">cred_spread &lt;-<span class="st"> </span>data_ml <span class="op">%&gt;%</span><span class="st">                                  </span><span class="co"># Create vector of spreads</span></a>
<a class="sourceLine" id="cb231-7" data-line-number="7"><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(date) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb231-8" data-line-number="8"><span class="st">    </span><span class="kw">left_join</span>(cred_spread, <span class="dt">by =</span> <span class="st">&quot;date&quot;</span>) </a>
<a class="sourceLine" id="cb231-9" data-line-number="9">feat_cred_spread &lt;-<span class="st"> </span>feat_cred_spread <span class="op">*</span><span class="st">                      </span><span class="co"># This product creates...</span></a>
<a class="sourceLine" id="cb231-10" data-line-number="10"><span class="st">    </span><span class="kw">matrix</span>(cred_spread<span class="op">$</span>spread,                              <span class="co"># the new values...</span></a>
<a class="sourceLine" id="cb231-11" data-line-number="11">           <span class="kw">length</span>(cred_spread<span class="op">$</span>spread),                      <span class="co"># using duplicated...</span></a>
<a class="sourceLine" id="cb231-12" data-line-number="12">           <span class="kw">length</span>(features_short))                          <span class="co"># columns</span></a>
<a class="sourceLine" id="cb231-13" data-line-number="13"><span class="kw">colnames</span>(feat_cred_spread) &lt;-<span class="st"> </span>names_cred_spread             <span class="co"># New column names</span></a>
<a class="sourceLine" id="cb231-14" data-line-number="14">data_cond &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(data_cond, feat_cred_spread)         <span class="co"># Aggregate old &amp; new</span></a>
<a class="sourceLine" id="cb231-15" data-line-number="15">data_cond <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Eps_cred_spread)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>() <span class="co"># Plot example</span></a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex5b"></span>
<img src="ML_factor_files/figure-html/ex5b-1.png" alt="Distribution of Eps after conditioning." width="400px" height="150px" />
<p class="caption">
FIGURE B.4: Distribution of Eps after conditioning.
</p>
</div>
<p></p>
<p>To prevent this issue, uniformization is required.</p>

<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb232-1" data-line-number="1">data_cond &lt;-<span class="st"> </span>data_cond <span class="op">%&gt;%</span><span class="st">                   </span><span class="co"># From new dataset</span></a>
<a class="sourceLine" id="cb232-2" data-line-number="2"><span class="st">    </span><span class="kw">group_by</span>(date) <span class="op">%&gt;%</span><span class="st">                       </span><span class="co"># Group by date and...</span></a>
<a class="sourceLine" id="cb232-3" data-line-number="3"><span class="st">    </span><span class="kw">mutate_at</span>(names_cred_spread, norm_unif)  <span class="co"># Uniformize the new features</span></a>
<a class="sourceLine" id="cb232-4" data-line-number="4">data_cond <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Eps_cred_spread)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">100</span>) <span class="co"># Verification</span></a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex51c"></span>
<img src="ML_factor_files/figure-html/ex51c-1.png" alt="Distribution of uniformized conditioned feature values." width="400px" height="150px" />
<p class="caption">
FIGURE B.5: Distribution of uniformized conditioned feature values.
</p>
</div>
<p></p>
<p>The second question naturally requires the downloading of VIX series first and the joining with the original data.</p>

<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb233-1" data-line-number="1"><span class="kw">getSymbols.FRED</span>(<span class="st">&quot;VIXCLS&quot;</span>,                           <span class="co"># Extract data</span></a>
<a class="sourceLine" id="cb233-2" data-line-number="2">                <span class="dt">env =</span> <span class="st">&quot;.GlobalEnv&quot;</span>, </a>
<a class="sourceLine" id="cb233-3" data-line-number="3">                <span class="dt">return.class =</span> <span class="st">&quot;xts&quot;</span>)</a></code></pre></div>
<pre><code>## [1] &quot;VIXCLS&quot;</code></pre>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb235-1" data-line-number="1">vix &lt;-<span class="st"> </span><span class="kw">fortify</span>(VIXCLS)                              <span class="co"># Transform to dataframe</span></a>
<a class="sourceLine" id="cb235-2" data-line-number="2"><span class="kw">colnames</span>(vix) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;date&quot;</span>, <span class="st">&quot;vix&quot;</span>)                   <span class="co"># Change column name</span></a>
<a class="sourceLine" id="cb235-3" data-line-number="3">vix &lt;-<span class="st"> </span>vix <span class="op">%&gt;%</span><span class="st">                                      </span><span class="co"># Take extraction and...</span></a>
<a class="sourceLine" id="cb235-4" data-line-number="4"><span class="st">    </span><span class="kw">full_join</span>(data_ml <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(date), <span class="dt">by =</span> <span class="st">&quot;date&quot;</span>) <span class="op">%&gt;%</span><span class="st">    </span><span class="co"># Join! </span></a>
<a class="sourceLine" id="cb235-5" data-line-number="5"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">vix =</span> <span class="kw">na.locf</span>(vix))                      <span class="co"># Replace NA by previous</span></a>
<a class="sourceLine" id="cb235-6" data-line-number="6">vix &lt;-<span class="st"> </span>vix[<span class="op">!</span><span class="kw">duplicated</span>(vix),]                       <span class="co"># Remove duplicates</span></a>
<a class="sourceLine" id="cb235-7" data-line-number="7">vix &lt;-<span class="st"> </span>data_ml <span class="op">%&gt;%</span><span class="st">                                  </span><span class="co"># Keep original data format</span></a>
<a class="sourceLine" id="cb235-8" data-line-number="8"><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(date) <span class="op">%&gt;%</span><span class="st">                         </span><span class="co"># ...</span></a>
<a class="sourceLine" id="cb235-9" data-line-number="9"><span class="st">    </span><span class="kw">left_join</span>(vix, <span class="dt">by =</span> <span class="st">&quot;date&quot;</span>)                     <span class="co"># Via left_join()</span></a></code></pre></div>
<p></p>
<p>We can then proceed with the categorization. We create the vector label in a new (smaller) dataset but not attached to the large data_ml variable. Also, we check the balance of labels and its evolution through time.</p>

<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb236-1" data-line-number="1">delta &lt;-<span class="st"> </span><span class="fl">0.5</span>                                       <span class="co"># Magnitude of vix correction</span></a>
<a class="sourceLine" id="cb236-2" data-line-number="2">vix_bar &lt;-<span class="st"> </span><span class="kw">median</span>(vix<span class="op">$</span>vix)                         <span class="co"># Median of vix</span></a>
<a class="sourceLine" id="cb236-3" data-line-number="3">data_vix &lt;-<span class="st"> </span>data_ml <span class="op">%&gt;%</span><span class="st">                            </span><span class="co"># Smaller dataset</span></a>
<a class="sourceLine" id="cb236-4" data-line-number="4"><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(stock_id, date, R1M_Usd) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb236-5" data-line-number="5"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">r_minus =</span> (<span class="op">-</span><span class="fl">0.02</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>delta<span class="op">*</span>(vix<span class="op">$</span>vix<span class="op">-</span>vix_bar)),  <span class="co"># r_-</span></a>
<a class="sourceLine" id="cb236-6" data-line-number="6">           <span class="dt">r_plus =</span> <span class="fl">0.02</span> <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(delta<span class="op">*</span>(vix<span class="op">$</span>vix<span class="op">-</span>vix_bar)))       <span class="co"># r_+</span></a>
<a class="sourceLine" id="cb236-7" data-line-number="7">data_vix &lt;-<span class="st"> </span>data_vix <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb236-8" data-line-number="8"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">R1M_Usd_Cvix =</span> <span class="kw">if_else</span>(R1M_Usd <span class="op">&lt;</span><span class="st"> </span>r_minus, <span class="dv">-1</span>,       <span class="co"># New label!</span></a>
<a class="sourceLine" id="cb236-9" data-line-number="9">                                  <span class="kw">if_else</span>(R1M_Usd <span class="op">&gt;</span><span class="st"> </span>r_plus, <span class="dv">1</span>,<span class="dv">0</span>)),</a>
<a class="sourceLine" id="cb236-10" data-line-number="10">           <span class="dt">R1M_Usd_Cvix =</span> <span class="kw">as.factor</span>(R1M_Usd_Cvix))</a>
<a class="sourceLine" id="cb236-11" data-line-number="11">data_vix <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb236-12" data-line-number="12"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">year =</span> <span class="kw">year</span>(date)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb236-13" data-line-number="13"><span class="st">    </span><span class="kw">group_by</span>(year, R1M_Usd_Cvix) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb236-14" data-line-number="14"><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">nb =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb236-15" data-line-number="15"><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> nb, <span class="dt">fill =</span> R1M_Usd_Cvix)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_col</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex52b"></span>
<img src="ML_factor_files/figure-html/ex52b-1.png" alt="Evolution of categories through time." width="400px" height="150px" />
<p class="caption">
FIGURE B.6: Evolution of categories through time.
</p>
</div>
<p></p>
<p>Finally, we switch to the outliers.
</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb237-1" data-line-number="1">data_ml <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb237-2" data-line-number="2"><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> R12M_Usd)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>()</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex53a"></span>
<img src="ML_factor_files/figure-html/ex53a-1.png" alt="Outliers in the dependent variable." width="400px" height="150px" />
<p class="caption">
FIGURE B.7: Outliers in the dependent variable.
</p>
</div>
<p></p>
<p>Returns above 50 should indeed be rare.</p>

<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb238-1" data-line-number="1">data_ml <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(R12M_Usd <span class="op">&gt;</span><span class="st"> </span><span class="dv">50</span>) <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(stock_id, date, R12M_Usd)</a></code></pre></div>
<pre><code>## # A tibble: 8 x 3
##   stock_id date       R12M_Usd
##      &lt;int&gt; &lt;date&gt;        &lt;dbl&gt;
## 1      212 2000-12-31     53.0
## 2      221 2008-12-31     53.5
## 3      221 2009-01-31     55.2
## 4      221 2009-02-28     54.8
## 5      296 2002-06-30     72.2
## 6      683 2009-02-28     96.0
## 7      683 2009-03-31     64.8
## 8      862 2009-02-28     58.0</code></pre>
<p></p>
<p>The largest return comes from stock #683. Lets have a look at the stream of monthly returns in 2009.</p>

<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb240-1" data-line-number="1">data_ml <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb240-2" data-line-number="2"><span class="st">    </span><span class="kw">filter</span>(stock_id <span class="op">==</span><span class="st"> </span><span class="dv">683</span>, <span class="kw">year</span>(date) <span class="op">==</span><span class="st"> </span><span class="dv">2009</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb240-3" data-line-number="3"><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(date, R1M_Usd)</a></code></pre></div>
<pre><code>## # A tibble: 12 x 2
##    date       R1M_Usd
##    &lt;date&gt;       &lt;dbl&gt;
##  1 2009-01-31  -0.625
##  2 2009-02-28   0.472
##  3 2009-03-31   1.44 
##  4 2009-04-30   0.139
##  5 2009-05-31   0.086
##  6 2009-06-30   0.185
##  7 2009-07-31   0.363
##  8 2009-08-31   0.103
##  9 2009-09-30   9.91 
## 10 2009-10-31   0.101
## 11 2009-11-30   0.202
## 12 2009-12-31  -0.251</code></pre>
<p></p>
<p>The returns are all very high. The annual value is plausible. In addition, a quick glance at the Vol1Y values show that the stock is the most volatile of the dataset.</p>
</div>
<div id="chapter-6" class="section level2">
<h2><span class="header-section-number">B.3</span> Chapter 6</h2>
<p>We recycle the training ans testing data variables created in the chapter (coding section notably). In addition, we create a dedicated function and resort to the <em>map2</em>() function from the <em>purrr</em> package.</p>

<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb242-1" data-line-number="1">alpha_seq &lt;-<span class="st"> </span>(<span class="dv">0</span><span class="op">:</span><span class="dv">10</span>)<span class="op">/</span><span class="dv">10</span>                     <span class="co"># Sequence of alpha values</span></a>
<a class="sourceLine" id="cb242-2" data-line-number="2">lambda_seq &lt;-<span class="st"> </span><span class="fl">0.1</span><span class="op">^</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>)                    <span class="co"># Sequence of lambda values</span></a>
<a class="sourceLine" id="cb242-3" data-line-number="3">pars &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(alpha_seq, lambda_seq) <span class="co"># Exploring all combinations!</span></a>
<a class="sourceLine" id="cb242-4" data-line-number="4">alpha_seq &lt;-<span class="st"> </span>pars[,<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb242-5" data-line-number="5">lambda_seq &lt;-<span class="st"> </span>pars[,<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb242-6" data-line-number="6">lasso_sens &lt;-<span class="st"> </span><span class="cf">function</span>(alpha, lambda, x_train, y_train, x_test, y_test){ <span class="co"># Function</span></a>
<a class="sourceLine" id="cb242-7" data-line-number="7">    fit_temp &lt;-<span class="st"> </span><span class="kw">glmnet</span>(x_train, y_train,                                 <span class="co"># Model</span></a>
<a class="sourceLine" id="cb242-8" data-line-number="8">                       <span class="dt">alpha =</span> alpha, <span class="dt">lambda =</span> lambda)</a>
<a class="sourceLine" id="cb242-9" data-line-number="9">    <span class="kw">return</span>(<span class="kw">sqrt</span>(<span class="kw">mean</span>((<span class="kw">predict</span>(fit_temp, x_test) <span class="op">-</span><span class="st"> </span>y_test)<span class="op">^</span><span class="dv">2</span>)))           <span class="co"># Output</span></a>
<a class="sourceLine" id="cb242-10" data-line-number="10">}</a>
<a class="sourceLine" id="cb242-11" data-line-number="11">rmse_elas &lt;-<span class="st"> </span><span class="kw">map2</span>(alpha_seq, lambda_seq, lasso_sens,                     <span class="co"># Automation</span></a>
<a class="sourceLine" id="cb242-12" data-line-number="12">                  <span class="dt">x_train =</span> x_penalized_train, <span class="dt">y_train =</span> y_penalized_train,</a>
<a class="sourceLine" id="cb242-13" data-line-number="13">                  <span class="dt">x_test =</span> x_penalized_test, <span class="dt">y_test =</span> testing_sample<span class="op">$</span>R1M_Usd)</a>
<a class="sourceLine" id="cb242-14" data-line-number="14"></a>
<a class="sourceLine" id="cb242-15" data-line-number="15"><span class="kw">bind_cols</span>(<span class="dt">alpha =</span> alpha_seq, <span class="dt">lambda =</span> <span class="kw">as.factor</span>(lambda_seq), <span class="dt">rmse =</span> <span class="kw">unlist</span>(rmse_elas)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb242-16" data-line-number="16"><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> alpha, <span class="dt">y =</span> rmse, <span class="dt">fill =</span> lambda)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_col</span>() <span class="op">+</span><span class="st"> </span><span class="kw">facet_grid</span>(lambda <span class="op">~</span>.) <span class="op">+</span></a>
<a class="sourceLine" id="cb242-17" data-line-number="17"><span class="st">    </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">0.19</span>,<span class="fl">0.193</span>))</a></code></pre></div>
<div class="figure"><span id="fig:ex61"></span>
<img src="ML_factor_files/figure-html/ex61-1.png" alt="Performance of elasticnet across parameter values." width="432" />
<p class="caption">
FIGURE B.8: Performance of elasticnet across parameter values.
</p>
</div>
<p></p>
<p>The parameters have a very marginal impact. Maybe the model is not a good fit for the task.</p>
</div>
<div id="chapter-7" class="section level2">
<h2><span class="header-section-number">B.4</span> Chapter 7</h2>

<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb243-1" data-line-number="1">fit1 &lt;-<span class="st"> </span><span class="kw">rpart</span>(formula, </a>
<a class="sourceLine" id="cb243-2" data-line-number="2">              <span class="dt">data =</span> training_sample,     <span class="co"># Data source: full sample</span></a>
<a class="sourceLine" id="cb243-3" data-line-number="3">              <span class="dt">cp =</span> <span class="fl">0.001</span>)                 <span class="co"># Precision: smaller = more leaves</span></a>
<a class="sourceLine" id="cb243-4" data-line-number="4"><span class="kw">mean</span>((<span class="kw">predict</span>(fit1, testing_sample) <span class="op">-</span><span class="st"> </span>testing_sample<span class="op">$</span>R1M_Usd)<span class="op">^</span><span class="dv">2</span>) </a></code></pre></div>
<pre><code>## [1] 0.04018973</code></pre>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb245-1" data-line-number="1">fit2 &lt;-<span class="st"> </span><span class="kw">rpart</span>(formula,</a>
<a class="sourceLine" id="cb245-2" data-line-number="2">              <span class="dt">data =</span> training_sample,     <span class="co"># Data source: full sample</span></a>
<a class="sourceLine" id="cb245-3" data-line-number="3">              <span class="dt">cp =</span> <span class="fl">0.01</span>)                  <span class="co"># Precision: smaller = more leaves</span></a>
<a class="sourceLine" id="cb245-4" data-line-number="4"><span class="kw">mean</span>((<span class="kw">predict</span>(fit2, testing_sample) <span class="op">-</span><span class="st"> </span>testing_sample<span class="op">$</span>R1M_Usd)<span class="op">^</span><span class="dv">2</span>) <span class="co"># Test!</span></a></code></pre></div>
<pre><code>## [1] 0.03699696</code></pre>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb247-1" data-line-number="1"><span class="kw">rpart.plot</span>(fit1)                         <span class="co"># Plot the first tree</span></a></code></pre></div>
<p><img src="ML_factor_files/figure-html/ex71-1.png" width="480" style="display: block; margin: auto;" /></p>
<p></p>
<p>The first model is <strong>too</strong> precise: going into the details of the training sample does not translate to good performance out-of-sample. The second, simpler model, yields better results.</p>

<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb248-1" data-line-number="1">n_trees &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">80</span>, <span class="dv">160</span>)</a>
<a class="sourceLine" id="cb248-2" data-line-number="2">mse_RF &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb248-3" data-line-number="3"><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(n_trees)){       <span class="co"># No need for functional programming here...</span></a>
<a class="sourceLine" id="cb248-4" data-line-number="4">    fit_temp &lt;-<span class="st"> </span><span class="kw">randomForest</span>(</a>
<a class="sourceLine" id="cb248-5" data-line-number="5">        <span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="st">&quot;R1M_Usd ~&quot;</span>, <span class="kw">paste</span>(features_short, <span class="dt">collapse =</span> <span class="st">&quot; + &quot;</span>))),  <span class="co"># New formula!</span></a>
<a class="sourceLine" id="cb248-6" data-line-number="6">        <span class="dt">data =</span> training_sample,    <span class="co"># Data source: training sample</span></a>
<a class="sourceLine" id="cb248-7" data-line-number="7">        <span class="dt">sampsize =</span> <span class="dv">30000</span>,          <span class="co"># Size of (random) sample for each tree</span></a>
<a class="sourceLine" id="cb248-8" data-line-number="8">        <span class="dt">replace =</span> <span class="ot">TRUE</span>,            <span class="co"># Is the sampling done with replacement?</span></a>
<a class="sourceLine" id="cb248-9" data-line-number="9">        <span class="dt">ntree =</span> n_trees[j],        <span class="co"># Nb of random trees</span></a>
<a class="sourceLine" id="cb248-10" data-line-number="10">        <span class="dt">mtry =</span> <span class="dv">5</span>)                  <span class="co"># Nb of predictors for each tree</span></a>
<a class="sourceLine" id="cb248-11" data-line-number="11">    mse_RF[j] &lt;-<span class="st"> </span><span class="kw">mean</span>((<span class="kw">predict</span>(fit_temp, testing_sample) <span class="op">-</span><span class="st"> </span>testing_sample<span class="op">$</span>R1M_Usd)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb248-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb248-13" data-line-number="13">mse_RF</a></code></pre></div>
<pre><code>## [1] 0.03934095 0.03933126 0.03744253 0.03719188 0.03713165</code></pre>
<p></p>
<p>Trees are by definition random so results can vary from test to test. Overall, large number of trees are preferable and the reason is that each new tree tell a new story and diversifies the risk of the whole forest. Some more technical details of why that may be the case are outlined in the original paper <span class="citation">Breiman (<a href="#ref-breiman2001random">2001</a>)</span>.</p>
<p>For the last exercises, we recycle the <em>formula</em> used in Chapter <a href="trees.html#trees">7</a>.</p>

<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb250-1" data-line-number="1">tree_<span class="dv">2008</span> &lt;-<span class="st"> </span><span class="kw">rpart</span>(formula,</a>
<a class="sourceLine" id="cb250-2" data-line-number="2">                   <span class="dt">data =</span> data_ml <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">year</span>(date) <span class="op">==</span><span class="st"> </span><span class="dv">2008</span>), <span class="co"># Data source: 2008</span></a>
<a class="sourceLine" id="cb250-3" data-line-number="3">                   <span class="dt">cp =</span> <span class="fl">0.001</span>,</a>
<a class="sourceLine" id="cb250-4" data-line-number="4">                   <span class="dt">maxdepth =</span> <span class="dv">2</span>) </a>
<a class="sourceLine" id="cb250-5" data-line-number="5"><span class="kw">rpart.plot</span>(tree_<span class="dv">2008</span>)</a></code></pre></div>
<p><img src="ML_factor_files/figure-html/ex73a-1.png" width="384" style="display: block; margin: auto;" /></p>
<p></p>
<p>The first splitting criterion is enterprise value (EV). EV is an indicator that adjusts market capitalization by substracting debt and adding cash. It is a more faithful account of the true value of a company. In 2008, the companies that fared the least bad where those with the highest EV (i.e., large, robust firms).</p>

<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb251-1" data-line-number="1">tree_<span class="dv">2009</span> &lt;-<span class="st"> </span><span class="kw">rpart</span>(formula,</a>
<a class="sourceLine" id="cb251-2" data-line-number="2">                   <span class="dt">data =</span> data_ml <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">year</span>(date) <span class="op">==</span><span class="st"> </span><span class="dv">2009</span>), <span class="co"># Data source: 2009</span></a>
<a class="sourceLine" id="cb251-3" data-line-number="3">                   <span class="dt">cp =</span> <span class="fl">0.001</span>,</a>
<a class="sourceLine" id="cb251-4" data-line-number="4">                   <span class="dt">maxdepth =</span> <span class="dv">2</span>) </a>
<a class="sourceLine" id="cb251-5" data-line-number="5"><span class="kw">rpart.plot</span>(tree_<span class="dv">2009</span>)</a></code></pre></div>
<p><img src="ML_factor_files/figure-html/ex73b-1.png" width="384" style="display: block; margin: auto;" /></p>
<p></p>
<p>In 2009, the firms that recovered the fastest were those that experienced high volatility in the past (likely, downwards volatility). Momentum is also very important: the firms with the lowest past returns are those that rebound the fastest. This is a typical example of the momentum crash phenomenon studied in <span class="citation">Barroso and Santa-Clara (<a href="#ref-barroso2015momentum">2015</a>)</span> and <span class="citation">Daniel and Moskowitz (<a href="#ref-daniel2016momentum">2016</a>)</span>. The rationale is the following: after a market downturn, the stock with the most potential for growth are those that have suffered the largest losses. Consequently, the negative (short) leg of the momentum factor performs very well, often better than the long leg. And indeed, being long in the momentum factor in 2009 would have generated negative profits.</p>
</div>
<div id="chapter-8-the-autoencoder-model" class="section level2">
<h2><span class="header-section-number">B.5</span> Chapter 8: the autoencoder model</h2>
<p>First, it is imperative to format the inputs properly. To avoid any issues, we work with perfectly rectangular data and hence restrict the investment set to the stocks with no missing points. Dimensions must also be in the correct order.</p>

<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb252-1" data-line-number="1">data_short &lt;-<span class="st"> </span>data_ml <span class="op">%&gt;%</span><span class="st">         </span><span class="co"># Shorter dataset</span></a>
<a class="sourceLine" id="cb252-2" data-line-number="2"><span class="st">    </span><span class="kw">filter</span>(stock_id <span class="op">%in%</span><span class="st"> </span>stock_ids_short) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb252-3" data-line-number="3"><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="kw">c</span>(<span class="st">&quot;stock_id&quot;</span>, <span class="st">&quot;date&quot;</span>,features_short, <span class="st">&quot;R1M_Usd&quot;</span>))</a>
<a class="sourceLine" id="cb252-4" data-line-number="4">dates &lt;-<span class="st"> </span><span class="kw">unique</span>(data_short<span class="op">$</span>date)  <span class="co"># Vector of dates</span></a>
<a class="sourceLine" id="cb252-5" data-line-number="5"></a>
<a class="sourceLine" id="cb252-6" data-line-number="6">N &lt;-<span class="st"> </span><span class="kw">length</span>(stock_ids_short)      <span class="co"># Dimension for assets</span></a>
<a class="sourceLine" id="cb252-7" data-line-number="7">Tt &lt;-<span class="st"> </span><span class="kw">length</span>(dates)               <span class="co"># Dimension for dates</span></a>
<a class="sourceLine" id="cb252-8" data-line-number="8">K &lt;-<span class="st"> </span><span class="kw">length</span>(features_short)       <span class="co"># Dimension for features</span></a>
<a class="sourceLine" id="cb252-9" data-line-number="9"></a>
<a class="sourceLine" id="cb252-10" data-line-number="10">factor_data &lt;-<span class="st"> </span>data_short <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># Factor side date</span></a>
<a class="sourceLine" id="cb252-11" data-line-number="11"><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(date, stock_id, R1M_Usd) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb252-12" data-line-number="12"><span class="st">    </span><span class="kw">spread</span>(<span class="dt">key =</span> stock_id, <span class="dt">value =</span> R1M_Usd) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb252-13" data-line-number="13"><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>date) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb252-14" data-line-number="14"><span class="st">    </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb252-15" data-line-number="15"></a>
<a class="sourceLine" id="cb252-16" data-line-number="16">beta_data &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">unlist</span>(data_short <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># Beta side data: beware the permutation below!</span></a>
<a class="sourceLine" id="cb252-17" data-line-number="17"><span class="st">                              </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>stock_id, <span class="op">-</span>date, <span class="op">-</span>R1M_Usd)), </a>
<a class="sourceLine" id="cb252-18" data-line-number="18">                   <span class="dt">dim =</span> <span class="kw">c</span>(N, Tt, K))</a>
<a class="sourceLine" id="cb252-19" data-line-number="19">beta_data &lt;-<span class="st"> </span><span class="kw">aperm</span>(beta_data, <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">3</span>))   <span class="co"># Permutation</span></a></code></pre></div>
<p></p>
<p>Next, we turn to the specification of the network, using a functional API form.</p>

<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb253-1" data-line-number="1">main_input &lt;-<span class="st"> </span><span class="kw">layer_input</span>(<span class="dt">shape =</span> <span class="kw">c</span>(N), <span class="dt">name =</span> <span class="st">&quot;main_input&quot;</span>)  <span class="co"># Main input: returns      </span></a>
<a class="sourceLine" id="cb253-2" data-line-number="2">factor_network &lt;-<span class="st"> </span>main_input <span class="op">%&gt;%</span><span class="st">                              </span><span class="co"># Def of factor side network</span></a>
<a class="sourceLine" id="cb253-3" data-line-number="3"><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">8</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="dt">name =</span> <span class="st">&quot;layer_1_r&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb253-4" data-line-number="4"><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">4</span>, <span class="dt">activation =</span> <span class="st">&quot;tanh&quot;</span>, <span class="dt">name =</span> <span class="st">&quot;layer_2_r&quot;</span>) </a>
<a class="sourceLine" id="cb253-5" data-line-number="5"></a>
<a class="sourceLine" id="cb253-6" data-line-number="6">aux_input &lt;-<span class="st"> </span><span class="kw">layer_input</span>(<span class="dt">shape =</span> <span class="kw">c</span>(N,K), <span class="dt">name =</span> <span class="st">&quot;aux_input&quot;</span>)  <span class="co"># Aux input: characteristics</span></a>
<a class="sourceLine" id="cb253-7" data-line-number="7">beta_network &lt;-<span class="st"> </span>aux_input <span class="op">%&gt;%</span><span class="st">                                 </span><span class="co"># Def of beta side network</span></a>
<a class="sourceLine" id="cb253-8" data-line-number="8"><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">8</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="dt">name =</span> <span class="st">&quot;layer_1_l&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb253-9" data-line-number="9"><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">4</span>, <span class="dt">activation =</span> <span class="st">&quot;tanh&quot;</span>, <span class="dt">name =</span> <span class="st">&quot;layer_2_l&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb253-10" data-line-number="10"><span class="st">    </span><span class="kw">layer_permute</span>(<span class="dt">dims =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="dt">name =</span> <span class="st">&quot;layer_3_l&quot;</span>)          <span class="co"># Permutation!</span></a>
<a class="sourceLine" id="cb253-11" data-line-number="11"></a>
<a class="sourceLine" id="cb253-12" data-line-number="12">main_output &lt;-<span class="st"> </span><span class="kw">layer_dot</span>(<span class="kw">c</span>(beta_network, factor_network),     <span class="co"># Product of 2 networks</span></a>
<a class="sourceLine" id="cb253-13" data-line-number="13">                         <span class="dt">axes =</span> <span class="dv">1</span>, <span class="dt">name =</span> <span class="st">&quot;main_output&quot;</span>) </a>
<a class="sourceLine" id="cb253-14" data-line-number="14"></a>
<a class="sourceLine" id="cb253-15" data-line-number="15">model_ae &lt;-<span class="st"> </span><span class="kw">keras_model</span>(                                      <span class="co"># AE Model specs</span></a>
<a class="sourceLine" id="cb253-16" data-line-number="16">    <span class="dt">inputs =</span> <span class="kw">c</span>(main_input, aux_input),</a>
<a class="sourceLine" id="cb253-17" data-line-number="17">    <span class="dt">outputs =</span> <span class="kw">c</span>(main_output)</a>
<a class="sourceLine" id="cb253-18" data-line-number="18">)</a></code></pre></div>
<p></p>
<p>Finally, we ask for the structure of the model, and train it.</p>

<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb254-1" data-line-number="1"><span class="kw">summary</span>(model_ae)                      <span class="co"># See model details / architecture</span></a></code></pre></div>
<pre><code>## __________________________________________________________________________________________
## Layer (type)                 Output Shape        Param #    Connected to                  
## ==========================================================================================
## aux_input (InputLayer)       (None, 793, 7)      0                                        
## __________________________________________________________________________________________
## layer_1_l (Dense)            (None, 793, 8)      64         aux_input[0][0]               
## __________________________________________________________________________________________
## main_input (InputLayer)      (None, 793)         0                                        
## __________________________________________________________________________________________
## layer_2_l (Dense)            (None, 793, 4)      36         layer_1_l[0][0]               
## __________________________________________________________________________________________
## layer_1_r (Dense)            (None, 8)           6352       main_input[0][0]              
## __________________________________________________________________________________________
## layer_3_l (Permute)          (None, 4, 793)      0          layer_2_l[0][0]               
## __________________________________________________________________________________________
## layer_2_r (Dense)            (None, 4)           36         layer_1_r[0][0]               
## __________________________________________________________________________________________
## main_output (Dot)            (None, 793)         0          layer_3_l[0][0]               
##                                                             layer_2_r[0][0]               
## ==========================================================================================
## Total params: 6,488
## Trainable params: 6,488
## Non-trainable params: 0
## __________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb256-1" data-line-number="1">model_ae <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(                  <span class="co"># Learning parameters</span></a>
<a class="sourceLine" id="cb256-2" data-line-number="2">    <span class="dt">optimizer =</span> <span class="st">&quot;rmsprop&quot;</span>,</a>
<a class="sourceLine" id="cb256-3" data-line-number="3">    <span class="dt">loss =</span> <span class="st">&quot;mse&quot;</span></a>
<a class="sourceLine" id="cb256-4" data-line-number="4">)</a>
<a class="sourceLine" id="cb256-5" data-line-number="5"></a>
<a class="sourceLine" id="cb256-6" data-line-number="6">model_ae <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(                      <span class="co"># Learning function</span></a>
<a class="sourceLine" id="cb256-7" data-line-number="7">    <span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">main_input =</span> factor_data, <span class="dt">aux_input =</span> beta_data),</a>
<a class="sourceLine" id="cb256-8" data-line-number="8">    <span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">main_output =</span> factor_data),</a>
<a class="sourceLine" id="cb256-9" data-line-number="9">    <span class="dt">epochs =</span> <span class="dv">20</span>,                      <span class="co"># Nb rounds</span></a>
<a class="sourceLine" id="cb256-10" data-line-number="10">    <span class="dt">batch_size =</span> <span class="dv">49</span>                   <span class="co"># Nb obs. per round</span></a>
<a class="sourceLine" id="cb256-11" data-line-number="11">)</a></code></pre></div>
<p></p>
</div>
<div id="chapter-9" class="section level2">
<h2><span class="header-section-number">B.6</span> Chapter 9</h2>
<p>Since we are going to reproduce a similar analysis several times, lets simplify the task with 2 tips. First, by using default parameter values that will be passed as common arguments to the <em>svm</em> function. Second, by creating a custom function that computes the MSE. Third, by resorting to functional calculus via the <em>map</em> function from the <em>purrr</em> package.</p>

<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb257-1" data-line-number="1">mse &lt;-<span class="st"> </span><span class="cf">function</span>(fit, features, label){             <span class="co"># MSE function</span></a>
<a class="sourceLine" id="cb257-2" data-line-number="2">    <span class="kw">return</span>(<span class="kw">mean</span>((<span class="kw">predict</span>(fit, features)<span class="op">-</span>label)<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb257-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb257-4" data-line-number="4">par_list &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">y =</span> train_label_xgb[<span class="dv">1</span><span class="op">:</span><span class="dv">10000</span>],     <span class="co"># From Tree chapter</span></a>
<a class="sourceLine" id="cb257-5" data-line-number="5">                 <span class="dt">x =</span> train_features_xgb[<span class="dv">1</span><span class="op">:</span><span class="dv">10000</span>,],</a>
<a class="sourceLine" id="cb257-6" data-line-number="6">                 <span class="dt">type =</span> <span class="st">&quot;eps-regression&quot;</span>,</a>
<a class="sourceLine" id="cb257-7" data-line-number="7">                 <span class="dt">epsilon =</span> <span class="fl">0.1</span>,                    <span class="co"># Width of strip for errors</span></a>
<a class="sourceLine" id="cb257-8" data-line-number="8">                 <span class="dt">gamma =</span> <span class="fl">0.5</span>,                      <span class="co"># Constant in the radial kernel </span></a>
<a class="sourceLine" id="cb257-9" data-line-number="9">                 <span class="dt">cost =</span> <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb257-10" data-line-number="10">svm_par &lt;-<span class="st"> </span><span class="cf">function</span>(kernel, par_list){             <span class="co"># Function for SVM fit automation</span></a>
<a class="sourceLine" id="cb257-11" data-line-number="11">    <span class="kw">require</span>(e1071)</a>
<a class="sourceLine" id="cb257-12" data-line-number="12">    <span class="kw">return</span>(<span class="kw">do.call</span>(svm, <span class="kw">c</span>(<span class="dt">kernel =</span> kernel, par_list))) </a>
<a class="sourceLine" id="cb257-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb257-14" data-line-number="14">kernels &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;linear&quot;</span>, <span class="st">&quot;radial&quot;</span>, <span class="st">&quot;polynomial&quot;</span>, <span class="st">&quot;sigmoid&quot;</span>) <span class="co"># Kernels</span></a>
<a class="sourceLine" id="cb257-15" data-line-number="15">fit_svm_par &lt;-<span class="st"> </span><span class="kw">map</span>(kernels, svm_par, <span class="dt">par_list =</span> par_list) <span class="co"># SVM models</span></a>
<a class="sourceLine" id="cb257-16" data-line-number="16"><span class="kw">map</span>(fit_svm_par, mse,                                     <span class="co"># MSEs</span></a>
<a class="sourceLine" id="cb257-17" data-line-number="17">    <span class="dt">features =</span> test_feat_short,                           <span class="co"># From SVM chapter </span></a>
<a class="sourceLine" id="cb257-18" data-line-number="18">    <span class="dt">label =</span> testing_sample<span class="op">$</span>R1M_Usd)</a></code></pre></div>
<pre><code>## [[1]]
## [1] 0.03849786
## 
## [[2]]
## [1] 0.03924576
## 
## [[3]]
## [1] 0.03951328
## 
## [[4]]
## [1] 334.8173</code></pre>
<p></p>
<p>The first two kernels yield the best fit while the last one should be avoided. Note that apart from the linear kernel, all other options require parameters. We have used the default ones, which may explain the poor performance of some nonlinear kernels.</p>
</div>
<div id="chapter-12-ensemble-neural-network" class="section level2">
<h2><span class="header-section-number">B.7</span> Chapter 12: ensemble neural network</h2>
<p>First, we create the two feature sets.</p>

<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb259-1" data-line-number="1">feat_train_<span class="dv">1</span> &lt;-<span class="st"> </span>training_sample <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(features[<span class="dv">1</span><span class="op">:</span><span class="dv">45</span>]) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># First set of features</span></a>
<a class="sourceLine" id="cb259-2" data-line-number="2"><span class="st">    </span><span class="kw">as.matrix</span>() </a>
<a class="sourceLine" id="cb259-3" data-line-number="3">feat_train_<span class="dv">2</span> &lt;-<span class="st"> </span>training_sample <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(features[<span class="dv">46</span><span class="op">:</span><span class="dv">90</span>]) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># Second set of features</span></a>
<a class="sourceLine" id="cb259-4" data-line-number="4"><span class="st">    </span><span class="kw">as.matrix</span>() </a>
<a class="sourceLine" id="cb259-5" data-line-number="5">feat_test_<span class="dv">1</span> &lt;-<span class="st"> </span>testing_sample <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(features[<span class="dv">1</span><span class="op">:</span><span class="dv">45</span>]) <span class="op">%&gt;%</span><span class="st">    </span><span class="co"># Test features 1</span></a>
<a class="sourceLine" id="cb259-6" data-line-number="6"><span class="st">    </span><span class="kw">as.matrix</span>() </a>
<a class="sourceLine" id="cb259-7" data-line-number="7">feat_test_<span class="dv">2</span> &lt;-<span class="st"> </span>testing_sample <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(features[<span class="dv">46</span><span class="op">:</span><span class="dv">90</span>]) <span class="op">%&gt;%</span><span class="st">   </span><span class="co"># Test features 2</span></a>
<a class="sourceLine" id="cb259-8" data-line-number="8"><span class="st">    </span><span class="kw">as.matrix</span>() </a></code></pre></div>
<p></p>
<p>Then, we specify the network structure.</p>

<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb260-1" data-line-number="1">first_input &lt;-<span class="st"> </span><span class="kw">layer_input</span>(<span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">45</span>), <span class="dt">name =</span> <span class="st">&quot;first_input&quot;</span>)  <span class="co"># First input      </span></a>
<a class="sourceLine" id="cb260-2" data-line-number="2">first_network &lt;-<span class="st"> </span>first_input <span class="op">%&gt;%</span><span class="st">                                 </span><span class="co"># Def of 1st network</span></a>
<a class="sourceLine" id="cb260-3" data-line-number="3"><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">8</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="dt">name =</span> <span class="st">&quot;layer_1&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb260-4" data-line-number="4"><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">2</span>, <span class="dt">activation =</span> <span class="st">&#39;softmax&#39;</span>)               <span class="co"># Softmax for categ. output</span></a>
<a class="sourceLine" id="cb260-5" data-line-number="5">second_input &lt;-<span class="st"> </span><span class="kw">layer_input</span>(<span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">45</span>), <span class="dt">name =</span> <span class="st">&quot;second_input&quot;</span>) <span class="co"># Second input      </span></a>
<a class="sourceLine" id="cb260-6" data-line-number="6">second_network &lt;-<span class="st"> </span>second_input <span class="op">%&gt;%</span><span class="st">                               </span><span class="co"># Def of 2nd network</span></a>
<a class="sourceLine" id="cb260-7" data-line-number="7"><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">8</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="dt">name =</span> <span class="st">&quot;layer_2&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb260-8" data-line-number="8"><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">2</span>, <span class="dt">activation =</span> <span class="st">&#39;softmax&#39;</span>)               <span class="co"># Softmax for categ. output</span></a>
<a class="sourceLine" id="cb260-9" data-line-number="9"></a>
<a class="sourceLine" id="cb260-10" data-line-number="10">main_output &lt;-<span class="st"> </span><span class="kw">layer_concatenate</span>(<span class="kw">c</span>(first_network, second_network)) <span class="op">%&gt;%</span><span class="st">   </span><span class="co"># Combination</span></a>
<a class="sourceLine" id="cb260-11" data-line-number="11"><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">2</span>, <span class="dt">activation =</span> <span class="st">&#39;softmax&#39;</span>, <span class="dt">name =</span> <span class="st">&#39;main_output&#39;</span>)</a>
<a class="sourceLine" id="cb260-12" data-line-number="12"></a>
<a class="sourceLine" id="cb260-13" data-line-number="13">model_ens &lt;-<span class="st"> </span><span class="kw">keras_model</span>(                                      <span class="co"># Agg. Model specs</span></a>
<a class="sourceLine" id="cb260-14" data-line-number="14">    <span class="dt">inputs =</span> <span class="kw">c</span>(first_input, second_input),</a>
<a class="sourceLine" id="cb260-15" data-line-number="15">    <span class="dt">outputs =</span> <span class="kw">c</span>(main_output)</a>
<a class="sourceLine" id="cb260-16" data-line-number="16">)</a></code></pre></div>
<p></p>
<p>Lastly, we can train and evaluate.</p>

<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb261-1" data-line-number="1"><span class="kw">summary</span>(model_ens)                      <span class="co"># See model details / architecture</span></a></code></pre></div>
<pre><code>## __________________________________________________________________________________________
## Layer (type)                 Output Shape        Param #    Connected to                  
## ==========================================================================================
## first_input (InputLayer)     (None, 45)          0                                        
## __________________________________________________________________________________________
## second_input (InputLayer)    (None, 45)          0                                        
## __________________________________________________________________________________________
## layer_1 (Dense)              (None, 8)           368        first_input[0][0]             
## __________________________________________________________________________________________
## layer_2 (Dense)              (None, 8)           368        second_input[0][0]            
## __________________________________________________________________________________________
## dense_38 (Dense)             (None, 2)           18         layer_1[0][0]                 
## __________________________________________________________________________________________
## dense_39 (Dense)             (None, 2)           18         layer_2[0][0]                 
## __________________________________________________________________________________________
## concatenate_1 (Concatenate)  (None, 4)           0          dense_38[0][0]                
##                                                             dense_39[0][0]                
## __________________________________________________________________________________________
## main_output (Dense)          (None, 2)           10         concatenate_1[0][0]           
## ==========================================================================================
## Total params: 782
## Trainable params: 782
## Non-trainable params: 0
## __________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb263-1" data-line-number="1">model_ens <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(                  <span class="co"># Learning parameters</span></a>
<a class="sourceLine" id="cb263-2" data-line-number="2">    <span class="dt">optimizer =</span> <span class="kw">optimizer_adam</span>(),</a>
<a class="sourceLine" id="cb263-3" data-line-number="3">    <span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>,</a>
<a class="sourceLine" id="cb263-4" data-line-number="4">    <span class="dt">metrics =</span> <span class="st">&quot;categorical_accuracy&quot;</span></a>
<a class="sourceLine" id="cb263-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb263-6" data-line-number="6"></a>
<a class="sourceLine" id="cb263-7" data-line-number="7">fit_NN_ens &lt;-<span class="st"> </span>model_ens <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(               <span class="co"># Learning function</span></a>
<a class="sourceLine" id="cb263-8" data-line-number="8">    <span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">first_input =</span> feat_train_<span class="dv">1</span>, </a>
<a class="sourceLine" id="cb263-9" data-line-number="9">             <span class="dt">second_input =</span> feat_train_<span class="dv">2</span>),</a>
<a class="sourceLine" id="cb263-10" data-line-number="10">    <span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">main_output =</span> NN_train_labels_C), <span class="co"># Recycled from NN Chapter</span></a>
<a class="sourceLine" id="cb263-11" data-line-number="11">    <span class="dt">epochs =</span> <span class="dv">12</span>,                               <span class="co"># Nb rounds</span></a>
<a class="sourceLine" id="cb263-12" data-line-number="12">    <span class="dt">batch_size =</span> <span class="dv">512</span>,                          <span class="co"># Nb obs. per round</span></a>
<a class="sourceLine" id="cb263-13" data-line-number="13">    <span class="dt">validation_data =</span> <span class="kw">list</span>(<span class="kw">list</span>(feat_test_<span class="dv">1</span>, feat_test_<span class="dv">2</span>),</a>
<a class="sourceLine" id="cb263-14" data-line-number="14">                           NN_test_labels_C)</a>
<a class="sourceLine" id="cb263-15" data-line-number="15">)</a>
<a class="sourceLine" id="cb263-16" data-line-number="16"><span class="kw">plot</span>(fit_NN_ens)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex12c"></span>
<img src="ML_factor_files/figure-html/ex12c-1.png" alt="Learning an integrated ensemble." width="432" />
<p class="caption">
FIGURE B.9: Learning an integrated ensemble.
</p>
</div>
<p></p>
</div>
<div id="chapter-13" class="section level2">
<h2><span class="header-section-number">B.8</span> Chapter 13</h2>
<div id="advanced-weighting-function" class="section level3">
<h3><span class="header-section-number">B.8.1</span> Advanced weighting function</h3>
<p>First, we code the function with all inputs.</p>

<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb264-1" data-line-number="1">weights &lt;-<span class="st"> </span><span class="cf">function</span>(Sigma, mu, Lambda, lambda, k_D, k_R, w_old){</a>
<a class="sourceLine" id="cb264-2" data-line-number="2">    N &lt;-<span class="st"> </span><span class="kw">nrow</span>(Sigma)</a>
<a class="sourceLine" id="cb264-3" data-line-number="3">    M &lt;-<span class="st"> </span><span class="kw">solve</span>(lambda<span class="op">*</span>Sigma <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>k_R<span class="op">*</span>Lambda <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>k_D<span class="op">*</span><span class="kw">diag</span>(N)) <span class="co"># Inverse matrix</span></a>
<a class="sourceLine" id="cb264-4" data-line-number="4">    num &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">sum</span>(M <span class="op">%*%</span><span class="st"> </span>(mu <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>k_R<span class="op">*</span>Lambda <span class="op">%*%</span><span class="st"> </span>w_old))       <span class="co"># eta numerator</span></a>
<a class="sourceLine" id="cb264-5" data-line-number="5">    den &lt;-<span class="st"> </span><span class="kw">sum</span>(M <span class="op">%*%</span><span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>,N))                              <span class="co"># eta denominator</span></a>
<a class="sourceLine" id="cb264-6" data-line-number="6">    eta &lt;-<span class="st"> </span>num <span class="op">/</span><span class="st"> </span>den                                        <span class="co"># eta</span></a>
<a class="sourceLine" id="cb264-7" data-line-number="7">    vec &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>eta <span class="op">*</span><span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>,N) <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>k_R<span class="op">*</span>Lambda <span class="op">%*%</span><span class="st"> </span>w_old     <span class="co"># Vector in weight</span></a>
<a class="sourceLine" id="cb264-8" data-line-number="8">    <span class="kw">return</span>(M <span class="op">%*%</span><span class="st"> </span>vec)</a>
<a class="sourceLine" id="cb264-9" data-line-number="9">}</a></code></pre></div>
<p></p>
<p>Second, we test it on some random dataset. We use the returns created at the end of Chapter <a href="notdata.html#notdata">2</a> and used for the Lasso allocation in Section <a href="lasso.html#sparseex">6.2.2</a>. For <span class="math inline">\(\boldsymbol{\mu}\)</span>, we use the sample average, which is rarely a good idea in practice. It serves as illustration only.</p>

<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb265-1" data-line-number="1">Sigma &lt;-<span class="st"> </span>returns <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>date) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">cov</span>()  <span class="co"># Covariance matrix</span></a>
<a class="sourceLine" id="cb265-2" data-line-number="2">mu &lt;-<span class="st"> </span>returns <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>date) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">apply</span>(<span class="dv">2</span>,mean)             <span class="co"># Vector of exp. returns</span></a>
<a class="sourceLine" id="cb265-3" data-line-number="3">Lambda &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="kw">nrow</span>(Sigma))                                          <span class="co"># Trans. Cost matrix</span></a>
<a class="sourceLine" id="cb265-4" data-line-number="4">lambda &lt;-<span class="st"> </span><span class="dv">1</span>                                                          <span class="co"># Risk aversion</span></a>
<a class="sourceLine" id="cb265-5" data-line-number="5">k_D &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb265-6" data-line-number="6">k_R &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb265-7" data-line-number="7">w_old &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">nrow</span>(Sigma)) <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(Sigma)                           <span class="co"># Prev. weights: EW</span></a>
<a class="sourceLine" id="cb265-8" data-line-number="8"><span class="kw">weights</span>(Sigma, mu, Lambda, lambda, k_D, k_R, w_old) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()       <span class="co"># First weights</span></a></code></pre></div>
<pre><code>##             [,1]
## 1   0.0031339308
## 3  -0.0003243527
## 4   0.0011944677
## 7   0.0014194215
## 9   0.0015086240
## 11 -0.0005015207</code></pre>
<p></p>
<p>Some weights can of course be negative. Finally, we use map2 to test some sensitivity. We examine 3 key indicators:<br />
- <strong>diversification</strong>, which we measure via the inverse of the sum of squared weights (inverse Hirschman-Herfindhal index);<br />
- <strong>leverage</strong>, which we assess via the absolute sum of negative weights;<br />
- <strong>in-sample volatility</strong>, which we compute as <span class="math inline">\(\textbf{w}&#39; \boldsymbol{\Sigma} \textbf{x}\)</span></p>
<p>To do so, we create a dedicated function below.</p>

<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb267-1" data-line-number="1">sensi &lt;-<span class="st"> </span><span class="cf">function</span>(lambda, k_D, Sigma, mu, Lambda, k_R, w_old){</a>
<a class="sourceLine" id="cb267-2" data-line-number="2">    w &lt;-<span class="st"> </span><span class="kw">weights</span>(Sigma, mu, Lambda, lambda, k_D, k_R, w_old)</a>
<a class="sourceLine" id="cb267-3" data-line-number="3">    out &lt;-<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb267-4" data-line-number="4">    out<span class="op">$</span>div &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="kw">sum</span>(w<span class="op">^</span><span class="dv">2</span>)             <span class="co"># Diversification</span></a>
<a class="sourceLine" id="cb267-5" data-line-number="5">    out<span class="op">$</span>lev &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(w[w<span class="op">&lt;</span><span class="dv">0</span>]))       <span class="co"># Leverage</span></a>
<a class="sourceLine" id="cb267-6" data-line-number="6">    out<span class="op">$</span>vol &lt;-<span class="st"> </span><span class="kw">t</span>(w) <span class="op">%*%</span><span class="st"> </span>Sigma <span class="op">%*%</span><span class="st"> </span>w   <span class="co"># In-sample vol</span></a>
<a class="sourceLine" id="cb267-7" data-line-number="7">    <span class="kw">return</span>(out)</a>
<a class="sourceLine" id="cb267-8" data-line-number="8">}</a></code></pre></div>
<p></p>
<p>Instead of using <em>map2</em>, we rely on a version that concatenates results into a dataframe directly.</p>

<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb268-1" data-line-number="1">lambda &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span>(<span class="op">-</span><span class="dv">3</span><span class="op">:</span><span class="dv">2</span>)              <span class="co"># parameter values</span></a>
<a class="sourceLine" id="cb268-2" data-line-number="2">k_D &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">*</span><span class="dv">10</span><span class="op">^</span>(<span class="op">-</span><span class="dv">3</span><span class="op">:</span><span class="dv">2</span>)               <span class="co"># parameter values</span></a>
<a class="sourceLine" id="cb268-3" data-line-number="3">pars &lt;-<span class="st"> </span><span class="kw">expand_grid</span>(lambda, k_D) <span class="co"># parameter grid</span></a>
<a class="sourceLine" id="cb268-4" data-line-number="4">lambda &lt;-<span class="st"> </span>pars<span class="op">$</span>lambda</a>
<a class="sourceLine" id="cb268-5" data-line-number="5">k_D &lt;-<span class="st"> </span>pars<span class="op">$</span>k_D</a>
<a class="sourceLine" id="cb268-6" data-line-number="6"></a>
<a class="sourceLine" id="cb268-7" data-line-number="7">res &lt;-<span class="st"> </span><span class="kw">map2_dfr</span>(lambda, k_D, sensi, </a>
<a class="sourceLine" id="cb268-8" data-line-number="8">                <span class="dt">Sigma =</span> Sigma, <span class="dt">mu =</span> mu, <span class="dt">Lambda =</span> Lambda, <span class="dt">k_R =</span> k_R, <span class="dt">w_old =</span> w_old)</a>
<a class="sourceLine" id="cb268-9" data-line-number="9"></a>
<a class="sourceLine" id="cb268-10" data-line-number="10"><span class="kw">bind_cols</span>(<span class="dt">lambda =</span> <span class="kw">as.factor</span>(lambda), <span class="dt">k_D =</span> <span class="kw">as.factor</span>(k_D), res) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb268-11" data-line-number="11"><span class="st">    </span><span class="kw">gather</span>(<span class="dt">key =</span> indicator, <span class="dt">value =</span> value, <span class="op">-</span>lambda, <span class="op">-</span>k_D) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb268-12" data-line-number="12"><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lambda, <span class="dt">y =</span> value, <span class="dt">fill =</span> k_D)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_col</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb268-13" data-line-number="13"><span class="st">    </span><span class="kw">facet_grid</span>(indicator <span class="op">~</span>. , <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)</a></code></pre></div>
<p><img src="ML_factor_files/figure-html/ex131d-1.png" width="432" style="display: block; margin: auto;" /></p>
<p></p>
<p>Each panel displays an indicator. In the first panel, we see that diversification increases with <span class="math inline">\(k_D\)</span>: indeed, as this number increases, the portfolio converges to uniform (EW) values. The parameter <span class="math inline">\(\lambda\)</span> has a minor impact. The second panel naturally shows the inverse effect for leverage: as diversification increases with <span class="math inline">\(k_D\)</span>, leverage (i.e., total negative positions - shortsales) decreases. Finally, the last panel shows that in-sample volatility is however largely driven by the risk aversion parameter. As <span class="math inline">\(\lambda\)</span> increases, volatility logically decreases. For small values of <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(k_D\)</span> is negatively related to volatility but the pattern reverses for large values of <span class="math inline">\(\lambda\)</span>. This is because the equally-weighted portfolio is less risky than very leveraged mean-variance policies, but more risky than the minimum-variance portfolio.</p>
</div>
<div id="functional-programming-in-the-backtest" class="section level3">
<h3><span class="header-section-number">B.8.2</span> Functional programming in the backtest</h3>

<p></p>
</div>
</div>
<div id="chapter-17" class="section level2">
<h2><span class="header-section-number">B.9</span> Chapter 17</h2>
<p>All we need to do is change the rho coefficient in the code of Chapter <a href="RL.html#RL">17</a>.</p>

<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb269-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">42</span>)                                                 <span class="co"># Fixing the random seed</span></a>
<a class="sourceLine" id="cb269-2" data-line-number="2">n_sample &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">5</span>                                             <span class="co"># Number of samples to be generated</span></a>
<a class="sourceLine" id="cb269-3" data-line-number="3">rho &lt;-<span class="st"> </span>(<span class="op">-</span><span class="fl">0.8</span>)                                                <span class="co"># Autoregressive parameter</span></a>
<a class="sourceLine" id="cb269-4" data-line-number="4">sd &lt;-<span class="st"> </span><span class="fl">0.4</span>                                                    <span class="co"># Std. dev. of noise</span></a>
<a class="sourceLine" id="cb269-5" data-line-number="5">a &lt;-<span class="st"> </span><span class="fl">0.06</span> <span class="op">*</span><span class="st"> </span>rho                                              <span class="co"># Scaled mean of returns</span></a>
<a class="sourceLine" id="cb269-6" data-line-number="6">data_RL3 &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">returns =</span> a<span class="op">/</span>rho <span class="op">+</span><span class="st"> </span><span class="kw">arima.sim</span>(<span class="dt">n =</span> n_sample, <span class="co"># Returns via AR(1) simulation</span></a>
<a class="sourceLine" id="cb269-7" data-line-number="7">                                               <span class="kw">list</span>(<span class="dt">ar =</span> rho),       </a>
<a class="sourceLine" id="cb269-8" data-line-number="8">                                               <span class="dt">sd =</span> sd),</a>
<a class="sourceLine" id="cb269-9" data-line-number="9">                   <span class="dt">action =</span> <span class="kw">round</span>(<span class="kw">runif</span>(n_sample)<span class="op">*</span><span class="dv">4</span>)<span class="op">/</span><span class="dv">4</span>) <span class="op">%&gt;%</span><span class="st">   </span><span class="co"># Random action (portfolio)</span></a>
<a class="sourceLine" id="cb269-10" data-line-number="10"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">new_state =</span> <span class="kw">if_else</span>(returns <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>, <span class="st">&quot;neg&quot;</span>, <span class="st">&quot;pos&quot;</span>),   <span class="co"># Coding of state</span></a>
<a class="sourceLine" id="cb269-11" data-line-number="11">           <span class="dt">reward =</span> returns <span class="op">*</span><span class="st"> </span>action,                        <span class="co"># Reward = portfolio return</span></a>
<a class="sourceLine" id="cb269-12" data-line-number="12">           <span class="dt">state =</span> <span class="kw">lag</span>(new_state),                           <span class="co"># Next state</span></a>
<a class="sourceLine" id="cb269-13" data-line-number="13">           <span class="dt">action =</span> <span class="kw">as.character</span>(action)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb269-14" data-line-number="14"><span class="st">    </span><span class="kw">na.omit</span>()                                                <span class="co"># Remove one missing state</span></a></code></pre></div>
<p></p>
<p>The learning can then proceed.</p>

<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb270-1" data-line-number="1">control &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="fl">0.1</span>,                        <span class="co"># Learning rate</span></a>
<a class="sourceLine" id="cb270-2" data-line-number="2">                <span class="dt">gamma =</span> <span class="fl">0.7</span>,                        <span class="co"># Discount factor for rewards</span></a>
<a class="sourceLine" id="cb270-3" data-line-number="3">                <span class="dt">epsilon =</span> <span class="fl">0.1</span>)                      <span class="co"># Exploration rate</span></a>
<a class="sourceLine" id="cb270-4" data-line-number="4">fit_RL3 &lt;-<span class="st"> </span><span class="kw">ReinforcementLearning</span>(data_RL3,          <span class="co"># Main RL function</span></a>
<a class="sourceLine" id="cb270-5" data-line-number="5">                                 <span class="dt">s =</span> <span class="st">&quot;state&quot;</span>, </a>
<a class="sourceLine" id="cb270-6" data-line-number="6">                                 <span class="dt">a =</span> <span class="st">&quot;action&quot;</span>, </a>
<a class="sourceLine" id="cb270-7" data-line-number="7">                                 <span class="dt">r =</span> <span class="st">&quot;reward&quot;</span>, </a>
<a class="sourceLine" id="cb270-8" data-line-number="8">                                 <span class="dt">s_new =</span> <span class="st">&quot;new_state&quot;</span>, </a>
<a class="sourceLine" id="cb270-9" data-line-number="9">                                 <span class="dt">control =</span> control)</a>
<a class="sourceLine" id="cb270-10" data-line-number="10"><span class="kw">print</span>(fit_RL3)   <span class="co"># Show the output</span></a></code></pre></div>
<pre><code>## State-Action function Q
##          0.25         0         1      0.75       0.5
## neg 0.7107268 0.5971710 1.4662416 0.9535698 0.8069591
## pos 0.7730842 0.7869229 0.4734467 0.4258593 0.6257039
## 
## Policy
## neg pos 
## &quot;1&quot; &quot;0&quot; 
## 
## Reward (last iteration)
## [1] 3013.162</code></pre>
<p></p>
<p>In this case, the constantly switching feature of the return process changes the outcome. The negative state is associated with large profits when the portfolio is fully invested while the positive state has the best average reward when the agent refrains from investing.</p>
<p>For the second exercise, the trick is to define all possible actions, that is all combinations (+1,0-1) for the two assets on all dates. We recycle the data from Chapter <a href="RL.html#RL">17</a>.</p>

<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb272-1" data-line-number="1">pos_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>)                              <span class="co"># Possible alloc. to asset 1</span></a>
<a class="sourceLine" id="cb272-2" data-line-number="2">pos_<span class="dv">4</span> &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>)                              <span class="co"># Possible alloc. to asset 3</span></a>
<a class="sourceLine" id="cb272-3" data-line-number="3">pos &lt;-<span class="st"> </span><span class="kw">expand_grid</span>(pos_<span class="dv">3</span>, pos_<span class="dv">4</span>)                <span class="co"># All combinations</span></a>
<a class="sourceLine" id="cb272-4" data-line-number="4">pos &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(pos, <span class="dt">id =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(pos))         <span class="co"># Adding combination id</span></a>
<a class="sourceLine" id="cb272-5" data-line-number="5"></a>
<a class="sourceLine" id="cb272-6" data-line-number="6">ret_pb_RL &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(<span class="dt">r3 =</span> return_<span class="dv">3</span>, <span class="dt">r4 =</span> return_<span class="dv">4</span>, <span class="co"># Returns &amp; P/B dataframe</span></a>
<a class="sourceLine" id="cb272-7" data-line-number="7">                        <span class="dt">pb3 =</span> pb_<span class="dv">3</span>, <span class="dt">pb4 =</span> pb_<span class="dv">4</span>) </a>
<a class="sourceLine" id="cb272-8" data-line-number="8">data_RL4 &lt;-<span class="st"> </span><span class="kw">sapply</span>(ret_pb_RL,                        <span class="co"># Combining return &amp; positions</span></a>
<a class="sourceLine" id="cb272-9" data-line-number="9">                   rep.int, </a>
<a class="sourceLine" id="cb272-10" data-line-number="10">                   <span class="dt">times =</span> <span class="kw">nrow</span>(pos)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb272-11" data-line-number="11"><span class="st">    </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb272-12" data-line-number="12"><span class="st">    </span><span class="kw">bind_cols</span>(<span class="dt">id =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(pos), <span class="dv">1</span>, <span class="dt">each =</span> <span class="kw">length</span>(return_<span class="dv">3</span>))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb272-13" data-line-number="13"><span class="st">    </span><span class="kw">left_join</span>(pos) <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>id) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb272-14" data-line-number="14"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">action =</span> <span class="kw">paste</span>(pos_<span class="dv">3</span>, pos_<span class="dv">4</span>),            <span class="co"># Uniting actions</span></a>
<a class="sourceLine" id="cb272-15" data-line-number="15">           <span class="dt">pb3 =</span> <span class="kw">round</span>(<span class="dv">5</span> <span class="op">*</span><span class="st"> </span>pb3),                    <span class="co"># Simplifying states</span></a>
<a class="sourceLine" id="cb272-16" data-line-number="16">           <span class="dt">pb4 =</span> <span class="kw">round</span>(<span class="dv">5</span> <span class="op">*</span><span class="st"> </span>pb4),                    <span class="co"># Simplifying states</span></a>
<a class="sourceLine" id="cb272-17" data-line-number="17">           <span class="dt">state =</span> <span class="kw">paste</span>(pb3, pb4),                 <span class="co"># Uniting states</span></a>
<a class="sourceLine" id="cb272-18" data-line-number="18">           <span class="dt">reward =</span> pos_<span class="dv">3</span><span class="op">*</span>r3 <span class="op">+</span><span class="st"> </span>pos_<span class="dv">4</span><span class="op">*</span>r4,            <span class="co"># Computing rewards</span></a>
<a class="sourceLine" id="cb272-19" data-line-number="19">           <span class="dt">new_state =</span> <span class="kw">lead</span>(state)) <span class="op">%&gt;%</span><span class="st">             </span><span class="co"># Infer new state</span></a>
<a class="sourceLine" id="cb272-20" data-line-number="20"><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>pb3, <span class="op">-</span>pb4, <span class="op">-</span>pos_<span class="dv">3</span>,          <span class="co"># Remove superfluous vars.</span></a>
<a class="sourceLine" id="cb272-21" data-line-number="21">                  <span class="op">-</span>pos_<span class="dv">4</span>, <span class="op">-</span>r3, <span class="op">-</span>r4) </a></code></pre></div>
<p></p>
<p>We can the plug this data into the RL function.</p>

<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb273-1" data-line-number="1">fit_RL4 &lt;-<span class="st"> </span><span class="kw">ReinforcementLearning</span>(data_RL4,           <span class="co"># Main RL function</span></a>
<a class="sourceLine" id="cb273-2" data-line-number="2">                               <span class="dt">s =</span> <span class="st">&quot;state&quot;</span>, </a>
<a class="sourceLine" id="cb273-3" data-line-number="3">                               <span class="dt">a =</span> <span class="st">&quot;action&quot;</span>, </a>
<a class="sourceLine" id="cb273-4" data-line-number="4">                               <span class="dt">r =</span> <span class="st">&quot;reward&quot;</span>, </a>
<a class="sourceLine" id="cb273-5" data-line-number="5">                               <span class="dt">s_new =</span> <span class="st">&quot;new_state&quot;</span>, </a>
<a class="sourceLine" id="cb273-6" data-line-number="6">                               <span class="dt">control =</span> control)</a>
<a class="sourceLine" id="cb273-7" data-line-number="7">fit_RL4<span class="op">$</span>Q &lt;-<span class="st"> </span><span class="kw">round</span>(fit_RL4<span class="op">$</span>Q, <span class="dv">3</span>) <span class="co"># Round the Q-matrix</span></a>
<a class="sourceLine" id="cb273-8" data-line-number="8"><span class="kw">print</span>(fit_RL4)                   <span class="co"># Show the output </span></a></code></pre></div>
<pre><code>## State-Action function Q
##        0 0    0 1  0 -1  -1 -1   -1 0   -1 1   1 -1    1 0    1 1
## X0.2 0.000  0.000 0.002 -0.017 -0.018 -0.020  0.023  0.025  0.024
## X0.3 0.001 -0.005 0.007 -0.013 -0.019 -0.026  0.031  0.027  0.021
## X3.1 0.003  0.003 0.003  0.002  0.002  0.003  0.002  0.002  0.003
## X2.1 0.027  0.038 0.020  0.004  0.015  0.039  0.013  0.021  0.041
## X2.2 0.021  0.014 0.027  0.038  0.047  0.045 -0.004 -0.011 -0.016
## X2.3 0.007  0.006 0.008  0.054  0.057  0.056 -0.041 -0.041 -0.041
## X1.1 0.027  0.054 0.005 -0.031 -0.005  0.041  0.025  0.046  0.072
## X1.2 0.019  0.020 0.020  0.015  0.023  0.029  0.012  0.014  0.023
## X1.3 0.008  0.019 0.000 -0.036 -0.027 -0.016  0.042  0.053  0.060
## 
## Policy
##   X0.2   X0.3   X3.1   X2.1   X2.2   X2.3   X1.1   X1.2   X1.3 
##  &quot;1 0&quot; &quot;1 -1&quot; &quot;0 -1&quot;  &quot;1 1&quot; &quot;-1 0&quot; &quot;-1 0&quot;  &quot;1 1&quot; &quot;-1 1&quot;  &quot;1 1&quot; 
## 
## Reward (last iteration)
## [1] 0</code></pre>
<p></p>
<p>The matrix is less sparse compared to the one of Chapter <a href="RL.html#RL">17</a>: we have covered much more ground!</p>

</div>
</div>
<h3><span class="header-section-number">C</span> References</h3>
<div id="refs" class="references">
<div id="ref-barroso2015momentum">
<p>Barroso, Pedro, and Pedro Santa-Clara. 2015. Momentum Has Its Moments. <em>Journal of Financial Economics</em> 116 (1): 11120.</p>
</div>
<div id="ref-breiman2001random">
<p>Breiman, Leo. 2001. Random Forests. <em>Machine Learning</em> 45 (1): 532.</p>
</div>
<div id="ref-daniel2016momentum">
<p>Daniel, Kent, and Tobias J Moskowitz. 2016. Momentum Crashes. <em>Journal of Financial Economics</em> 122 (2): 22147.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-description.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ML_factor.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
